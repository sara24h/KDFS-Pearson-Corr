import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
import os
from tqdm import tqdm
import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score
import sys
from model.pruned_model.ResNet_pruned import ResNet_50_pruned_hardfakevsreal


class WildDeepFakeDataset(Dataset):
    """Ø¯ÛŒØªØ§Ø³Øª Ø¨Ø±Ø§ÛŒ Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù† ØªØµØ§ÙˆÛŒØ± fake Ùˆ real"""
    
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.samples = []
        
        # Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø§Ø² Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ fake Ùˆ real
        for label, class_name in enumerate(['real', 'fake']):
            class_dir = os.path.join(root_dir, class_name)
            if os.path.exists(class_dir):
                for img_name in os.listdir(class_dir):
                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                        self.samples.append((
                            os.path.join(class_dir, img_name),
                            label
                        ))
        
        print(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù„ÙˆØ¯ Ø´Ø¯Ù‡ Ø§Ø² {root_dir}: {len(self.samples)}")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        image = Image.open(img_path).convert('RGB')
        
        if self.transform:
            image = self.transform(image)
        
        return image, torch.tensor(label, dtype=torch.float32)


def get_transforms(phase, mean, std):
    """ØªØ¹Ø±ÛŒÙ transformations Ø¨Ø±Ø§ÛŒ train Ùˆ validation/test"""
    
    if phase == 'train':
        return transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.RandomCrop(224),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(degrees=10),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
            transforms.ToTensor(),
            transforms.Normalize(mean=mean, std=std)
        ])
    else:
        return transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=mean, std=std)
        ])


def load_pruned_model(checkpoint_path, device):
    """Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡ Ø§Ø² checkpoint"""
    
    print(f"ğŸ“¥ Ø¯Ø± Ø­Ø§Ù„ Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„ Ø§Ø² {checkpoint_path}...")
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ masks Ø§Ø² checkpoint
    masks = checkpoint['masks']
    
    # Ø³Ø§Ø®Øª Ù…Ø¯Ù„ Ø¨Ø§ masks
    model = ResNet_50_pruned_hardfakevsreal(masks=masks)
    
    # Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù† weights
    model.load_state_dict(checkpoint['model_state_dict'])
    model = model.to(device)
    
    print(f"âœ… Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù„ÙˆØ¯ Ø´Ø¯!")
    print(f"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§: {sum(p.numel() for p in model.parameters()):,}")
    
    return model


def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch):

    model.train()
    running_loss = 0.0
    all_preds = []
    all_labels = []
    
    pbar = tqdm(dataloader, desc=f"ğŸš€ Epoch {epoch} [Train]")
    
    for images, labels in pbar:
        images, labels = images.to(device), labels.to(device)
        
        # Forward
        optimizer.zero_grad()
        outputs, _ = model(images)
        outputs = outputs.squeeze()
        loss = criterion(outputs, labels)
        
        # Backward
        loss.backward()
        optimizer.step()
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ metrics
        running_loss += loss.item()
        preds = (torch.sigmoid(outputs) > 0.5).float()
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())
        
        pbar.set_postfix({'loss': f"{loss.item():.4f}"})
    
    epoch_loss = running_loss / len(dataloader)
    epoch_acc = accuracy_score(all_labels, all_preds)
    
    return epoch_loss, epoch_acc


def validate(model, dataloader, criterion, device, phase='Valid'):
    """Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„ Ø±ÙˆÛŒ validation ÛŒØ§ test set"""
    
    model.eval()
    running_loss = 0.0
    all_preds = []
    all_probs = []
    all_labels = []
    
    pbar = tqdm(dataloader, desc=f"ğŸ” {phase}")
    
    with torch.no_grad():
        for images, labels in pbar:
            images, labels = images.to(device), labels.to(device)
            
            outputs, _ = model(images)
            outputs = outputs.squeeze()
            loss = criterion(outputs, labels)
            
            running_loss += loss.item()
            probs = torch.sigmoid(outputs)
            preds = (probs > 0.5).float()
            
            all_preds.extend(preds.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    epoch_loss = running_loss / len(dataloader)
    epoch_acc = accuracy_score(all_labels, all_preds)
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ metrics Ø§Ø¶Ø§ÙÛŒ
    precision, recall, f1, _ = precision_recall_fscore_support(
        all_labels, all_preds, average='binary', zero_division=0
    )
    auc = roc_auc_score(all_labels, all_probs)
    
    return {
        'loss': epoch_loss,
        'accuracy': epoch_acc,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'auc': auc
    }

def fine_tune(
    model_path,
    data_dir,
    output_dir,
    mean=[0.5207,0.4258,0.3806],
    std=[0.2490,0.2239,0.2212],
    batch_size=32,
    num_epochs=50,
    learning_rate=1e-4,
    weight_decay=1e-4,
    patience=10
):

    os.makedirs(output_dir, exist_ok=True)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    model = load_pruned_model(model_path, device)

    train_transform = get_transforms('train', mean, std)
    val_transform = get_transforms('val', mean, std)
    
    # Ù„ÙˆØ¯ Ø¯ÛŒØªØ§Ø³Øªâ€ŒÙ‡Ø§
    print("\nğŸ“ Ø¯Ø± Ø­Ø§Ù„ Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¯ÛŒØªØ§Ø³Øªâ€ŒÙ‡Ø§...")
    train_dataset = WildDeepFakeDataset(
        os.path.join(data_dir, 'train'),
        transform=train_transform
    )
    valid_dataset = WildDeepFakeDataset(
        os.path.join(data_dir, 'valid'),
        transform=val_transform
    )
    test_dataset = WildDeepFakeDataset(
        os.path.join(data_dir, 'test'),
        transform=val_transform
    )
    
    # DataLoaders
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4,
        pin_memory=True
    )
    valid_loader = DataLoader(
        valid_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )
    
    # ØªØ¹Ø±ÛŒÙ loss Ùˆ optimizer
    criterion = nn.BCEWithLogitsLoss()
    optimizer = optim.AdamW(
        model.parameters(),
        lr=learning_rate,
        weight_decay=weight_decay
    )
    
    # Learning rate scheduler
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer,
        mode='min',
        factor=0.5,
        patience=5,
        verbose=True
    )
    
    # Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ early stopping
    best_val_loss = float('inf')
    best_val_acc = 0.0
    epochs_no_improve = 0
    
    print("\n" + "="*70)
    print("ğŸš€ Ø´Ø±ÙˆØ¹ Fine-tuning")
    print("="*70)
    
    # Ø­Ù„Ù‚Ù‡ Ø¢Ù…ÙˆØ²Ø´
    for epoch in range(1, num_epochs + 1):
        print(f"\nğŸ“ Epoch {epoch}/{num_epochs}")
        print("-" * 70)
        
        # Ø¢Ù…ÙˆØ²Ø´
        train_loss, train_acc = train_one_epoch(
            model, train_loader, criterion, optimizer, device, epoch
        )
        
        # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
        val_metrics = validate(model, valid_loader, criterion, device, 'Valid')
        
        # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
        print(f"\nğŸ“Š Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}")
        print(f"ğŸ“Š Valid Loss: {val_metrics['loss']:.4f} | Valid Acc: {val_metrics['accuracy']:.4f}")
        print(f"ğŸ“Š Valid F1: {val_metrics['f1']:.4f} | Valid AUC: {val_metrics['auc']:.4f}")
        
        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ learning rate
        scheduler.step(val_metrics['loss'])
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
        if val_metrics['loss'] < best_val_loss:
            best_val_loss = val_metrics['loss']
            best_val_acc = val_metrics['accuracy']
            epochs_no_improve = 0
            
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'masks': model.masks if hasattr(model, 'masks') else None,
                'val_loss': best_val_loss,
                'val_acc': best_val_acc,
                'val_metrics': val_metrics
            }
            
            best_model_path = os.path.join(output_dir, 'best_model.pt')
            torch.save(checkpoint, best_model_path)
            print(f"ğŸ’¾ Ù…Ø¯Ù„ Ø¨Ù‡ØªØ±ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯! (Val Loss: {best_val_loss:.4f})")
        else:
            epochs_no_improve += 1
            print(f"â³ {epochs_no_improve}/{patience} epochs Ø¨Ø¯ÙˆÙ† Ø¨Ù‡Ø¨ÙˆØ¯")
        
        # Early stopping
        if epochs_no_improve >= patience:
            print(f"\nâ›” Early stopping! Ø¨Ù‡ØªØ±ÛŒÙ† Val Loss: {best_val_loss:.4f}")
            break
    
    # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø±ÙˆÛŒ test set
    print("\n" + "="*70)
    print("ğŸ§ª Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø±ÙˆÛŒ Test Set")
    print("="*70)
    
    # Ù„ÙˆØ¯ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
    best_checkpoint = torch.load(os.path.join(output_dir, 'best_model.pt'))
    model.load_state_dict(best_checkpoint['model_state_dict'])
    
    test_metrics = validate(model, test_loader, criterion, device, 'Test')
    
    print(f"\nğŸ¯ Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ:")
    print(f"   Test Loss:      {test_metrics['loss']:.4f}")
    print(f"   Test Accuracy:  {test_metrics['accuracy']:.4f}")
    print(f"   Test Precision: {test_metrics['precision']:.4f}")
    print(f"   Test Recall:    {test_metrics['recall']:.4f}")
    print(f"   Test F1-Score:  {test_metrics['f1']:.4f}")
    print(f"   Test AUC:       {test_metrics['auc']:.4f}")
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
    results = {
        'best_epoch': best_checkpoint['epoch'],
        'best_val_loss': best_val_loss,
        'best_val_acc': best_val_acc,
        'test_metrics': test_metrics
    }
    
    torch.save(results, os.path.join(output_dir, 'training_results.pt'))
    
    print(f"\nâœ… Fine-tuning ØªÙ…Ø§Ù… Ø´Ø¯!")
    print(f"ğŸ“ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ø± {output_dir} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯")
    
    return model, results


if __name__ == "__main__":
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª
    MODEL_PATH = '/kaggle/input/140k-pearson-pruned/pytorch/default/1/140k_pearson_pruned.pt'  # Ù…Ø³ÛŒØ± Ù…Ø¯Ù„ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡
    DATA_DIR = '/kaggle/input/20k-wild-deepfake-dataset/wild-dataset_20k'    # Ù…Ø³ÛŒØ± Ø¯ÛŒØªØ§Ø³Øª
    OUTPUT_DIR = '/kaggle/working/140k_finetuned_pruned_model' # Ù…Ø³ÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ
    

    MEAN = [0.5207,0.4258,0.3806]  # ImageNet defaults
    STD = [0.2490,0.2239,0.2212]   # ImageNet defaults

    model, results = fine_tune(
        model_path=MODEL_PATH,
        data_dir=DATA_DIR,
        output_dir=OUTPUT_DIR,
        mean=MEAN,
        std=STD,
        batch_size=32,
        num_epochs=50,
        learning_rate=1e-4,
        weight_decay=1e-4,
        patience=10
    )
