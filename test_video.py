import os
import time
import torch
import torch.nn as nn
from tqdm import tqdm
from collections import OrderedDict

from model.student.ResNet_sparse_video import ResNet_50_sparse_uadfv
from data.video_data import create_uadfv_dataloaders

def set_global_seed(seed: int):
    import random
    import numpy as np
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    print(f"Global seed set to {seed}")


class Test:
    def __init__(self, args):
        self.args = args
        self.dataset_dir = args.dataset_dir
        self.num_workers = args.num_workers
        self.pin_memory = args.pin_memory
        self.device = args.device
        self.test_batch_size = args.test_batch_size
        self.sparsed_student_ckpt_path = args.sparsed_student_ckpt_path
        self.dataset_mode = args.dataset_mode
        self.num_frames = getattr(args, 'num_frames', 32)
        self.image_size = 256

        # Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…Ø¯Ù„ Ù…Ø¹Ù„Ù… (Teacher)
        self.teacher_params = 23.51  # Ù…ÛŒÙ„ÛŒÙˆÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ±
        self.teacher_video_flops = 170.59  # GFLOPs Ø¨Ø±Ø§ÛŒ 32 ÙØ±ÛŒÙ…

        if self.device == 'cuda' and not torch.cuda.is_available():
            raise RuntimeError("CUDA is not available! Please check GPU setup.")

    def dataload(self):
        print(f"==> Loading {self.dataset_mode} test dataset..")
        if self.dataset_mode == 'uadfv':
            _, _, self.test_loader = create_uadfv_dataloaders(
                root_dir=self.dataset_dir,
                num_frames=self.num_frames,
                image_size=self.image_size,
                train_batch_size=1,
                eval_batch_size=self.test_batch_size,
                num_workers=self.num_workers,
                pin_memory=self.pin_memory,
                ddp=False,
                sampling_strategy='uniform'
            )
            print(f"{self.dataset_mode} test dataset loaded! Total batches: {len(self.test_loader)}")
        else:
            raise ValueError(f"This test script is currently configured only for 'uadfv' dataset mode.")

    def build_model(self):
        print("==> Building student model..")
        self.student = ResNet_50_sparse_uadfv()
        self.student.dataset_type = "uadfv" 
        
        if not os.path.exists(self.sparsed_student_ckpt_path):
            raise FileNotFoundError(f"Checkpoint file not found: {self.sparsed_student_ckpt_path}")
        
        print(f"\nØ¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ checkpoint Ø§Ø²: {self.sparsed_student_ckpt_path}")
        ckpt_student = torch.load(self.sparsed_student_ckpt_path, map_location="cpu", weights_only=True)
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­ØªÙˆØ§ÛŒ checkpoint
        print("Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± checkpoint:")
        for key in ckpt_student.keys():
            if isinstance(ckpt_student[key], dict):
                print(f"  - {key}: {len(ckpt_student[key])} Ø¢ÛŒØªÙ…")
            else:
                print(f"  - {key}: {type(ckpt_student[key])}")
        
        state_dict = ckpt_student.get("student", ckpt_student)
        
        if list(state_dict.keys())[0].startswith('module.'):
            new_state_dict = OrderedDict()
            for k, v in state_dict.items():
                name = k.replace('module.', '', 1)
                new_state_dict[name] = v
            state_dict = new_state_dict
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§ Ø¯Ø± state_dict
        mask_count = sum(1 for k in state_dict.keys() if 'mask' in k)
        print(f"\nØªØ¹Ø¯Ø§Ø¯ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§ Ø¯Ø± checkpoint: {mask_count}")
        if mask_count == 0:
            print("âš ï¸ Ù‡Ø´Ø¯Ø§Ø±: Ù‡ÛŒÚ† Ù…Ø§Ø³Ú©ÛŒ Ø¯Ø± checkpoint ÛŒØ§ÙØª Ù†Ø´Ø¯!")
            print("   Ù…Ø¯Ù„ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ prune Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        
        self.student.load_state_dict(state_dict, strict=True)
        self.student.to(self.device)
        print(f"Model loaded on {self.device}")

    def analyze_pruning_status(self):
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ù‚ÛŒÙ‚ ÙˆØ¶Ø¹ÛŒØª pruning Ù…Ø¯Ù„"""
        
        print("\n" + "="*80)
        print("ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª Pruning")
        print("="*80)
        
        has_masks = False
        mask_layers = []
        
        for name, module in self.student.named_modules():
            if hasattr(module, 'weight_mask'):
                has_masks = True
                mask = module.weight_mask
                total = mask.numel()
                active = torch.sum(mask).item()
                sparsity = (1 - active/total) * 100
                
                mask_layers.append({
                    'name': name,
                    'total': total,
                    'active': active,
                    'sparsity': sparsity
                })
        
        if not has_masks:
            print("âŒ Ù…Ø¯Ù„ ÙØ§Ù‚Ø¯ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§ÛŒ pruning Ø§Ø³Øª!")
            print("   Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª:")
            print("   1. Checkpoint Ù‚Ø¨Ù„ Ø§Ø² pruning Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª")
            print("   2. Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§ Ø¯Ø± checkpoint Ø°Ø®ÛŒØ±Ù‡ Ù†Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯")
            print("   3. ØªÙ†Ø¸ÛŒÙ… 'ticket=True' Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª - Ù†ÛŒØ§Ø² Ø¨Ù‡ apply_mask() Ø¯Ø§Ø±ÛŒØ¯")
            return False
        
        print(f"âœ“ ØªØ¹Ø¯Ø§Ø¯ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø±Ø§ÛŒ Ù…Ø§Ø³Ú©: {len(mask_layers)}")
        print("\nØ¬Ø²Ø¦ÛŒØ§Øª pruning Ù‡Ø± Ù„Ø§ÛŒÙ‡:")
        print("-"*80)
        
        total_weights = 0
        total_active = 0
        
        for layer in mask_layers[:10]:  # ÙÙ‚Ø· 10 Ù„Ø§ÛŒÙ‡ Ø§ÙˆÙ„ Ø±Ø§ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…
            print(f"{layer['name']:40s} | Sparsity: {layer['sparsity']:6.2f}% | "
                  f"Active: {layer['active']:8d}/{layer['total']:8d}")
            total_weights += layer['total']
            total_active += layer['active']
        
        if len(mask_layers) > 10:
            print(f"... Ùˆ {len(mask_layers)-10} Ù„Ø§ÛŒÙ‡ Ø¯ÛŒÚ¯Ø±")
            for layer in mask_layers[10:]:
                total_weights += layer['total']
                total_active += layer['active']
        
        overall_sparsity = (1 - total_active/total_weights) * 100
        print("-"*80)
        print(f"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ú©Ù„ÛŒ Sparsity: {overall_sparsity:.2f}%")
        print("="*80)
        
        return True

    def calculate_model_metrics(self):
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ù‚ÛŒÙ‚ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ùˆ FLOPs"""
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§
        total_params = sum(p.numel() for p in self.student.parameters())
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ ÙØ¹Ø§Ù„
        effective_params = 0
        for name, module in self.student.named_modules():
            if isinstance(module, (nn.Conv2d, nn.Linear)):
                if hasattr(module, 'weight_mask'):
                    effective_params += torch.sum(module.weight_mask).item()
                else:
                    effective_params += module.weight.numel()
                
                if module.bias is not None:
                    if hasattr(module, 'bias_mask'):
                        effective_params += torch.sum(module.bias_mask).item()
                    else:
                        effective_params += module.bias.numel()
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ BatchNorm Ùˆ ØºÛŒØ±Ù‡
        for name, param in self.student.named_parameters():
            module_name = '.'.join(name.split('.')[:-1])
            try:
                module = self.student.get_submodule(module_name) if module_name else self.student
                if not isinstance(module, (nn.Conv2d, nn.Linear)):
                    effective_params += param.numel()
            except:
                effective_params += param.numel()
        
        sparsity = (total_params - effective_params) / total_params * 100 if total_params > 0 else 0
        
        print("\n" + "="*80)
        print("Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:")
        print("-"*80)
        print(f"Ú©Ù„ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:         {total_params/1e6:8.2f} M")
        print(f"Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ ÙØ¹Ø§Ù„:       {effective_params/1e6:8.2f} M")
        print(f"Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡:    {(total_params-effective_params)/1e6:8.2f} M")
        print(f"Ù†Ø±Ø® Sparsity:          {sparsity:8.2f} %")
        print("="*80)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ FLOPs
        print("\nÙ…Ø­Ø§Ø³Ø¨Ù‡ FLOPs...")
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ØªØ¯ Ø¯Ø§Ø®Ù„ÛŒ
        try:
            # âš ï¸ IMPORTANT: Ø§ÛŒÙ† Ù…ØªØ¯ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ FLOPs ÛŒÚ© ÙØ±ÛŒÙ… sample Ø´Ø¯Ù‡ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯
            # Ù†Ù‡ Ú©Ù„ 32 ÙØ±ÛŒÙ…!
            student_flops_single = self.student.get_video_flops_sampled(
                num_sampled_frames=self.num_frames
            ) / 1e9
            
            print(f"âš ï¸ ØªÙˆØ¬Ù‡: Ù…ØªØ¯ get_video_flops_sampled Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ ÙÙ‚Ø· ÛŒÚ© ÙØ±ÛŒÙ… sample Ø´Ø¯Ù‡")
            print(f"   Ø±Ø§ Ø­Ø³Ø§Ø¨ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ù†Ù‡ Ú©Ù„ {self.num_frames} ÙØ±ÛŒÙ…!")
            print(f"   FLOPs Ú¯Ø²Ø§Ø±Ø´ Ø´Ø¯Ù‡: {student_flops_single:.2f} GFLOPs")
            
            # ØªØ®Ù…ÛŒÙ† FLOPs ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… ÙØ±ÛŒÙ…â€ŒÙ‡Ø§
            # ÙØ±Ø¶: Ø§Ú¯Ø± Ù…ØªØ¯ ÙÙ‚Ø· 1 ÙØ±ÛŒÙ… Ø±Ø§ Ø­Ø³Ø§Ø¨ Ú©Ø±Ø¯Ù‡ØŒ Ø¨Ø§ÛŒØ¯ Ø¯Ø± ØªØ¹Ø¯Ø§Ø¯ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§ Ø¶Ø±Ø¨ Ø´ÙˆØ¯
            estimated_total_flops = student_flops_single * self.num_frames
            print(f"   ØªØ®Ù…ÛŒÙ† FLOPs Ú©Ù„ ({self.num_frames} ÙØ±ÛŒÙ…): {estimated_total_flops:.2f} GFLOPs")
            
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¹Ø¯Ø¯ Ú©Ù…ØªØ± Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ù†ØµÙØ§Ù†Ù‡
            student_flops = student_flops_single
            
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ FLOPs: {e}")
            student_flops = 0.0
        
        return {
            'total_params': total_params / 1e6,
            'effective_params': effective_params / 1e6,
            'pruned_params': (total_params - effective_params) / 1e6,
            'sparsity': sparsity,
            'student_flops': student_flops,
            'estimated_total_flops': estimated_total_flops if 'estimated_total_flops' in locals() else student_flops
        }

    def test(self):
        self.student.eval()
        
        # ðŸ”§ FIX 1: Ø¨Ø±Ø±Ø³ÛŒ Ùˆ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ØµØ­ÛŒØ­ pruning
        print("\n" + "="*80)
        print("ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø­Ø§Ù„Øª Pruning")
        print("="*80)
        
        # Ø±ÙˆØ´ 1: ØªÙ†Ø¸ÛŒÙ… ticket
        self.student.ticket = True
        print("âœ“ ticket = True")
        
        # Ø±ÙˆØ´ 2: Ø§Ú¯Ø± Ù…ØªØ¯ apply_mask ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ø¢Ù† Ø±Ø§ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ú©Ù†ÛŒØ¯
        if hasattr(self.student, 'apply_mask'):
            self.student.apply_mask()
            print("âœ“ apply_mask() ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ø´Ø¯")
        
        # Ø±ÙˆØ´ 3: Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù…ØªØ¯ get_sparse_model
        if hasattr(self.student, 'get_sparse_model'):
            print("âš ï¸ ØªÙˆØ¬Ù‡: Ù…ØªØ¯ get_sparse_model() ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ - Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†ÛŒØ§Ø² Ø¨Ø§Ø´Ø¯ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ø´ÙˆØ¯")
        
        # ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª pruning
        has_pruning = self.analyze_pruning_status()
        
        if not has_pruning:
            print("\n" + "="*80)
            print("âš ï¸ Ù‡Ø´Ø¯Ø§Ø± Ù…Ù‡Ù…: Ù…Ø¯Ù„ prune Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª!")
            print("="*80)
            print("Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:")
            print("1. Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ checkpoint ØµØ­ÛŒØ­ Ø§Ø³Øª (Ø¨Ø¹Ø¯ Ø§Ø² pruning)")
            print("2. Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ø¢ÛŒØ§ Ø¨Ø§ÛŒØ¯ Ø§Ø² checkpoint Ø¯ÛŒÚ¯Ø±ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯")
            print("3. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†ÛŒØ§Ø² Ø¨Ø§Ø´Ø¯ script pruning Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯")
            print("="*80 + "\n")
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§
        metrics = self.calculate_model_metrics()
        
        # Ú¯Ø²Ø§Ø±Ø´ Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ
        print("\n" + "="*80)
        print("          Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ù…Ø¯Ù„ Ù…Ø¹Ù„Ù… (Teacher)")
        print("="*80)
        print(f"Ù…Ø¯Ù„ Ù…Ø¹Ù„Ù… (Teacher):")
        print(f"  - FLOPs (32 ÙØ±ÛŒÙ…):     {self.teacher_video_flops:8.2f} GFLOPs")
        print(f"  - Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:            {self.teacher_params:8.2f} M")
        print("-"*80)
        print(f"Ù…Ø¯Ù„ Ø¯Ø§Ù†Ø´Ø¬Ùˆ (Student):")
        print(f"  - FLOPs (Ú¯Ø²Ø§Ø±Ø´ Ø´Ø¯Ù‡):    {metrics['student_flops']:8.2f} GFLOPs")
        if 'estimated_total_flops' in metrics:
            print(f"  - FLOPs (ØªØ®Ù…ÛŒÙ†ÛŒ Ú©Ù„):    {metrics['estimated_total_flops']:8.2f} GFLOPs")
        print(f"  - Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ ÙØ¹Ø§Ù„:       {metrics['effective_params']:8.2f} M")
        print(f"  - Sparsity:             {metrics['sparsity']:8.2f} %")
        print("-"*80)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø§Ù‡Ø´ (Ø¨Ø§ FLOPs ØªØ®Ù…ÛŒÙ†ÛŒ)
        flops_for_comparison = metrics.get('estimated_total_flops', metrics['student_flops'])
        flops_reduction = ((self.teacher_video_flops - flops_for_comparison) / 
                          self.teacher_video_flops * 100)
        params_reduction = ((self.teacher_params - metrics['effective_params']) / 
                           self.teacher_params * 100)
        
        print(f"Ú©Ø§Ù‡Ø´ FLOPs:     {flops_reduction:7.2f} %")
        print(f"Ú©Ø§Ù‡Ø´ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§: {params_reduction:7.2f} %")
        print("="*80)
        
        # ØªØ³Øª Ø¯Ù‚Øª
        correct = 0
        total = 0
        with torch.no_grad():
            with tqdm(total=len(self.test_loader), ncols=100, desc="Testing") as _tqdm:
                for videos, targets in self.test_loader:
                    videos = videos.to(self.device, non_blocking=True)
                    targets = targets.to(self.device, non_blocking=True).float()
                    
                    batch_size, num_frames, C, H, W = videos.shape
                    videos_flat = videos.view(-1, C, H, W)

                    logits_student, _ = self.student(videos_flat)
                    logits_student = logits_student.view(batch_size, num_frames).mean(dim=1)
                    
                    preds = (torch.sigmoid(logits_student) > 0.5).float()
                    correct += (preds == targets).sum().item()
                    total += targets.size(0)

                    _tqdm.set_postfix(Acc=f"{(100.*correct/total):.2f}%")
                    _tqdm.update(1)

        final_acc = 100. * correct / total
        print(f"\n[Test] Final Accuracy on {self.dataset_mode} dataset: {final_acc:.2f}%")
        
        # Ø®Ù„Ø§ØµÙ‡ Ù†Ù‡Ø§ÛŒÛŒ
        print("\n" + "="*80)
        print("Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬:")
        print(f"  âœ“ Accuracy:         {final_acc:.2f}%")
        print(f"  âœ“ Ú©Ø§Ù‡Ø´ FLOPs:       {flops_reduction:.2f}%")
        print(f"  âœ“ Ú©Ø§Ù‡Ø´ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:   {params_reduction:.2f}%")
        print(f"  âœ“ Sparsity ÙˆØ§Ù‚Ø¹ÛŒ:   {metrics['sparsity']:.2f}%")
        
        if metrics['sparsity'] < 1.0:
            print("\n  âš ï¸ ØªÙˆØ¬Ù‡: Sparsity Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ ØµÙØ± Ø§Ø³Øª - Ù…Ø¯Ù„ prune Ù†Ø´Ø¯Ù‡!")
        
        print("="*80)

    def main(self):
        print(f"Starting test pipeline for dataset: {self.dataset_mode}")
        self.dataload()
        self.build_model()
        self.test()


class Args:
    def __init__(self):
        self.dataset_mode = 'uadfv'
        self.dataset_dir = '/kaggle/input/uadfv-dataset/UADFV'
        self.num_workers = 4
        self.pin_memory = True
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.test_batch_size = 8
        self.sparsed_student_ckpt_path = '/kaggle/working/results/run_resnet50_imagenet_prune1/student_model/resnet50_sparse_best.pt'
        self.num_frames = 32


if __name__ == '__main__':
    set_global_seed(42)
    args = Args()
    
    if not os.path.exists(args.sparsed_student_ckpt_path):
        print(f"ERROR: Student checkpoint not found at '{args.sparsed_student_ckpt_path}'")
        print("Please update the 'sparsed_student_ckpt_path' in the Args class.")
    else:
        test_pipeline = Test(args)
        test_pipeline.main()
