import torch
import torch.nn as nn
import sys
import os
sys.path.append('/kaggle/working')

# Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
try:
    from model.student.ResNet_sparse import ResNet_50_sparse_hardfakevsreal
    HAS_SPARSE_MODEL = True
except ImportError as e:
    print(f"âš ï¸ ØªÙˆØ¬Ù‡: Ù…Ø¯Ù„ sparse Ù‚Ø§Ø¨Ù„ import Ù†ÛŒØ³Øª: {e}")
    HAS_SPARSE_MODEL = False

from model.pruned_model.ResNet_pruned import ResNet_50_pruned_hardfakevsreal

checkpoint_path = '/kaggle/input/kdfs-10k-pearson-19-shahrivar-314-epochs/results/run_resnet50_imagenet_prune1/student_model/finetune_ResNet_50_sparse_best.pt'

print("="*70)
print("Ù…Ø±Ø­Ù„Ù‡ 1: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§ Ø§Ø² Ù…Ø¯Ù„ Sparse")
print("="*70)

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú†Ú©â€ŒÙ¾ÙˆÛŒÙ†Øª
checkpoint = torch.load(checkpoint_path, map_location='cpu')
sparse_state_dict = checkpoint['student']

masks = None
remaining_counts = None

# ==============================================================
# Ø±ÙˆØ´ 1: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² mask_modules (Ø§Ú¯Ø± Ù…Ø¯Ù„ sparse Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø¨Ø§Ø´Ø¯)
# ==============================================================

if HAS_SPARSE_MODEL:
    try:
        print("\nØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§ Ø§Ø² mask_modules...")
        sparse_model = ResNet_50_sparse_hardfakevsreal()
        sparse_model.load_state_dict(sparse_state_dict)
        
        if hasattr(sparse_model, 'mask_modules') and len(sparse_model.mask_modules) > 0:
            print(f"\nâœ… Ù…Ø¯Ù„ Ø´Ø§Ù…Ù„ {len(sparse_model.mask_modules)} mask_module Ø§Ø³Øª.")
            masks = []
            remaining_counts = []
            
            for i, mask_module in enumerate(sparse_model.mask_modules):
                mask_weight = mask_module.mask_weight  # ÛŒÚ© Ù¾Ø§Ø±Ø§Ù…ØªØ± torch
                shape = mask_weight.shape
                
                # ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ù…Ø§Ø³Ú©
                if len(shape) == 5 and shape[1] == 2:
                    # ÙØ±Ø¶: [1, 2, C, 1, 1] â†’ binary selection
                    mask_binary = torch.argmax(mask_weight, dim=1).squeeze()  # [C]
                elif len(shape) == 4:
                    # ÙØ±Ø¶: [1, C, 1, 1] â†’ continuous mask
                    mask_binary = (mask_weight.squeeze() > 0.5).float()
                else:
                    raise ValueError(f"Ø´Ú©Ù„ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ mask_weight: {shape}")
                
                mask = mask_binary.float()
                remaining = int(mask.sum().item())
                original = mask.shape[0]
                masks.append(mask)
                remaining_counts.append(remaining)
                print(f"Mask {i}: {remaining}/{original} ÙÛŒÙ„ØªØ± ÙØ¹Ø§Ù„")
            
            print(f"\nâœ… Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§ Ø§Ø² mask_modules Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù†Ø¯.")
        else:
            print("âŒ Ù…Ø¯Ù„ ÙØ§Ù‚Ø¯ mask_modules Ø§Ø³Øª. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† (norm-based).")
            HAS_SPARSE_MODEL = False
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² mask_modules: {e}")
        HAS_SPARSE_MODEL = False

# ==============================================================
# Ø±ÙˆØ´ 2: fallback Ø¨Ù‡ Ø±ÙˆØ´ norm-based (Ø§Ú¯Ø± mask_modules ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´Øª)
# ==============================================================

if masks is None:
    print("\nØ§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø§Ø³Ú© Ø§Ø² Ù†ÙØ±Ù… ÙÛŒÙ„ØªØ±Ù‡Ø§ (norm-based)...")
    
    def extract_masks_from_weights(state_dict):
        masks = []
        remaining_counts = []
        layer_configs = [('layer1', 3), ('layer2', 4), ('layer3', 6), ('layer4', 3)]
        print("\nØ§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§:\n")
        for layer_name, num_blocks in layer_configs:
            for block_idx in range(num_blocks):
                for conv_idx in range(1, 4):
                    weight_key = f'{layer_name}.{block_idx}.conv{conv_idx}.weight'
                    if weight_key in state_dict:
                        weight = state_dict[weight_key]
                        num_filters = weight.shape[0]
                        filter_norms = torch.norm(weight.view(num_filters, -1), p=1, dim=1)
                        mask = (filter_norms >= 1e-6).float()
                        remaining = int(mask.sum().item())
                        masks.append(mask)
                        remaining_counts.append(remaining)
                        print(f"{layer_name}.{block_idx}.conv{conv_idx}: {remaining}/{num_filters} ÙÛŒÙ„ØªØ±")
        return masks, remaining_counts

    masks, remaining_counts = extract_masks_from_weights(sparse_state_dict)

print(f"\nâœ… ØªØ¹Ø¯Ø§Ø¯ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡: {len(masks)}")
print(f"âœ… Ø¬Ù…Ø¹ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡: {sum(remaining_counts)}")

# Ù†Ù…Ø§ÛŒØ´ Ù„ÛŒØ³Øª ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡
print("\n" + "="*70)
print("ğŸ“‹ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡:")
print("="*70)
print("remaining_filters = [")
layer_names = []
for i in range(1, 5):
    num_blocks = [3, 4, 6, 3][i-1]
    for j in range(num_blocks):
        layer_names.append(f'layer{i}.{j}')
idx = 0
for layer_name in layer_names:
    layer_data = remaining_counts[idx:idx+3]
    print(f"    # {layer_name}")
    print(f"    {', '.join(map(str, layer_data))},")
    idx += 3
print("]")

# ===========================
# 2. Ø³Ø§Ø®Øª Ù…Ø¯Ù„ Pruned
# ===========================

print("\n" + "="*70)
print("Ù…Ø±Ø­Ù„Ù‡ 2: Ø³Ø§Ø®Øª Ù…Ø¯Ù„ Pruned")
print("="*70)

try:
    model_pruned = ResNet_50_pruned_hardfakevsreal(masks=masks)
    total_params = sum(p.numel() for p in model_pruned.parameters())
    print("âœ… Ù…Ø¯Ù„ pruned Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯!")
    print(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù…Ø¯Ù„ pruned: {total_params:,}")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Ù…Ø¯Ù„: {e}")
    import traceback
    traceback.print_exc()
    raise

# ===========================
# 3. Ù„ÙˆØ¯ ÙˆØ²Ù†â€ŒÙ‡Ø§ Ø¯Ø± Ù…Ø¯Ù„ Pruned
# ===========================

print("\n" + "="*70)
print("Ù…Ø±Ø­Ù„Ù‡ 3: Ù„ÙˆØ¯ ÙˆØ²Ù†â€ŒÙ‡Ø§ Ø¯Ø± Ù…Ø¯Ù„ Pruned")
print("="*70)

def load_pruned_weights(model_pruned, sparse_state_dict, masks):
    pruned_state_dict = {}
    
    # conv1, bn1
    for key in ['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 
                'bn1.running_var', 'bn1.num_batches_tracked']:
        if key in sparse_state_dict:
            pruned_state_dict[key] = sparse_state_dict[key]
    
    # fc
    for key in ['fc.weight', 'fc.bias']:
        if key in sparse_state_dict:
            pruned_state_dict[key] = sparse_state_dict[key]
    
    mask_idx = 0
    layer_configs = [('layer1', 3), ('layer2', 4), ('layer3', 6), ('layer4', 3)]
    print("\nÙ„ÙˆØ¯ ÙˆØ²Ù†â€ŒÙ‡Ø§:\n")
    
    for layer_name, num_blocks in layer_configs:
        for block_idx in range(num_blocks):
            for conv_idx in range(1, 4):
                sparse_conv_key = f'{layer_name}.{block_idx}.conv{conv_idx}.weight'
                sparse_bn_key = f'{layer_name}.{block_idx}.bn{conv_idx}.weight'
                
                if sparse_conv_key in sparse_state_dict:
                    sparse_weight = sparse_state_dict[sparse_conv_key]
                    mask = masks[mask_idx]
                    active_out = (mask == 1).nonzero(as_tuple=True)[0]
                    pruned_weight = sparse_weight[active_out]
                    
                    if conv_idx > 1 and mask_idx > 0:
                        prev_mask = masks[mask_idx - 1]
                        active_in = (prev_mask == 1).nonzero(as_tuple=True)[0]
                        pruned_weight = pruned_weight[:, active_in]
                    
                    pruned_state_dict[sparse_conv_key] = pruned_weight
                    print(f"{layer_name}.{block_idx}.conv{conv_idx}: {pruned_weight.shape}")
                    
                    # BatchNorm
                    if sparse_bn_key in sparse_state_dict:
                        for suffix in ['', '.bias', '.running_mean', '.running_var', '.num_batches_tracked']:
                            key = f'{layer_name}.{block_idx}.bn{conv_idx}' + suffix
                            if suffix == '':
                                key += '.weight'
                            if key in sparse_state_dict:
                                if 'num_batches_tracked' in key:
                                    pruned_state_dict[key] = sparse_state_dict[key]
                                else:
                                    pruned_state_dict[key] = sparse_state_dict[key][active_out]
                    mask_idx += 1
            
            # downsample
            downsample_conv_key = f'{layer_name}.{block_idx}.downsample.0.weight'
            if downsample_conv_key in sparse_state_dict:
                for suffix in ['.0.weight', '.1.weight', '.1.bias', '.1.running_mean', '.1.running_var', '.1.num_batches_tracked']:
                    key = f'{layer_name}.{block_idx}.downsample' + suffix
                    if key in sparse_state_dict:
                        pruned_state_dict[key] = sparse_state_dict[key]
    
    return pruned_state_dict

try:
    pruned_weights = load_pruned_weights(model_pruned, sparse_state_dict, masks)
    print(f"\nâœ… ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ pruned Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯: {len(pruned_weights)} Ú©Ù„ÛŒØ¯")
    missing, unexpected = model_pruned.load_state_dict(pruned_weights, strict=False)
    print(f"âœ… ÙˆØ²Ù†â€ŒÙ‡Ø§ Ù„ÙˆØ¯ Ø´Ø¯Ù†Ø¯")
    print(f"   - Missing keys: {len(missing)}")
    print(f"   - Unexpected keys: {len(unexpected)}")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù„ÙˆØ¯ ÙˆØ²Ù†â€ŒÙ‡Ø§: {e}")
    import traceback
    traceback.print_exc()
    raise

# ===========================
# 4. ØªØ³Øª Ù…Ø¯Ù„
# ===========================

print("\n" + "="*70)
print("Ù…Ø±Ø­Ù„Ù‡ 4: ØªØ³Øª Ù…Ø¯Ù„ Pruned")
print("="*70)

try:
    model_pruned.eval()
    with torch.no_grad():
        dummy_input = torch.randn(2, 3, 224, 224)
        output, features = model_pruned(dummy_input)
        print(f"âœ… ØªØ³Øª Ù…ÙˆÙÙ‚!")
        print(f"   - Ø´Ú©Ù„ output: {output.shape}")
        print(f"   - ØªØ¹Ø¯Ø§Ø¯ feature maps: {len(features)}")
        if features:
            print(f"   - Ø´Ú©Ù„ Ø§ÙˆÙ„ÛŒÙ† feature map: {features[0].shape}")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª: {e}")
    import traceback
    traceback.print_exc()
    raise

# ===========================
# 5. Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Pruned
# ===========================

print("\n" + "="*70)
print("Ù…Ø±Ø­Ù„Ù‡ 5: Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Pruned")
print("="*70)

try:
    save_path = '/kaggle/working/resnet50_pruned_model.pt'
    checkpoint_to_save = {
        'model_state_dict': model_pruned.state_dict(),
        'masks': masks,
        'remaining_counts': remaining_counts,
        'total_params': total_params,
        'model_architecture': 'ResNet_50_pruned_hardfakevsreal',
        'best_prec1': checkpoint.get('best_prec1_after_finetune', None)
    }
    torch.save(checkpoint_to_save, save_path)
    file_size_mb = os.path.getsize(save_path) / (1024 * 1024)
    print(f"âœ… Ù…Ø¯Ù„ Ú©Ø§Ù…Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø±: {save_path} ({file_size_mb:.2f} MB)")
    
    save_path_weights = '/kaggle/working/resnet50_pruned_weights_only.pt'
    torch.save(model_pruned.state_dict(), save_path_weights)
    file_size_weights_mb = os.path.getsize(save_path_weights) / (1024 * 1024)
    print(f"âœ… ÙÙ‚Ø· ÙˆØ²Ù†â€ŒÙ‡Ø§ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ ({file_size_weights_mb:.2f} MB)")

    print("\nğŸ“¦ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡:")
    print(f"   - ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§: {total_params:,}")
    print(f"   - ØªØ¹Ø¯Ø§Ø¯ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§: {len(masks)}")
    print(f"   - Ø¬Ù…Ø¹ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡: {sum(remaining_counts)}")
    if checkpoint_to_save['best_prec1']:
        print(f"   - Ø¨Ù‡ØªØ±ÛŒÙ† Ø¯Ù‚Øª: {checkpoint_to_save['best_prec1']:.2f}%")

    print("\nğŸ’¡ Ù†Ø­ÙˆÙ‡ Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù†:")
    print(f"checkpoint = torch.load('{save_path}')")
    print("model = ResNet_50_pruned_hardfakevsreal(masks=checkpoint['masks'])")
    print("model.load_state_dict(checkpoint['model_state_dict'])")

except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡: {e}")
    import traceback
    traceback.print_exc()

print("\n" + "="*70)
print("ğŸ‰ ØªÙ…Ø§Ù… Ù…Ø±Ø§Ø­Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!")
print("="*70)
