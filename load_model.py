import torch
import torch.nn as nn
import sys
sys.path.append('/kaggle/working')

from model.pruned_model.ResNet_pruned import ResNet_50_pruned_hardfakevsreal

checkpoint_path = '/kaggle/input/kdfs-10k-pearson-19-shahrivar-314-epochs/results/run_resnet50_imagenet_prune1/student_model/finetune_ResNet_50_sparse_best.pt'

print("="*70)
print("ØªØ­Ù„ÛŒÙ„ Ù†ÙˆØ¹ Pruning Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§")
print("="*70)

checkpoint = torch.load(checkpoint_path, map_location='cpu')
sparse_state_dict = checkpoint['student']

def analyze_pruning_type(state_dict):
    """
    ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ pruning: structured (filter-level) ÛŒØ§ unstructured (weight-level)
    """
    print("\nğŸ” ØªØ­Ù„ÛŒÙ„ Ù†ÙˆØ¹ pruning...")
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ú†Ù†Ø¯ Ù„Ø§ÛŒÙ‡ Ù†Ù…ÙˆÙ†Ù‡
    sample_keys = [k for k in state_dict.keys() if 'conv' in k and 'weight' in k][:5]
    
    structured_pruning = False
    unstructured_pruning = False
    
    for key in sample_keys:
        weight = state_dict[key]
        total_filters = weight.shape[0]
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØ§ ÙÛŒÙ„ØªØ± Ú©Ø§Ù…Ù„ Ø­Ø°Ù Ø´Ø¯Ù‡ (Ù‡Ù…Ù‡ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø¢Ù† ØµÙØ±)
        filters_all_zero = (weight.view(weight.shape[0], -1).abs().sum(dim=1) == 0).sum().item()
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØ§ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ individual ØµÙØ± Ø´Ø¯Ù†
        total_weights = weight.numel()
        zero_weights = (weight == 0).sum().item()
        sparsity = zero_weights / total_weights * 100
        
        print(f"\n  {key}:")
        print(f"    - Shape: {list(weight.shape)}")
        print(f"    - ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ú©Ø§Ù…Ù„Ø§Ù‹ ØµÙØ±: {filters_all_zero}/{total_filters}")
        print(f"    - Sparsity: {sparsity:.2f}%")
        
        if filters_all_zero > 0:
            structured_pruning = True
        if sparsity > 5:  # threshold Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ unstructured pruning
            unstructured_pruning = True
    
    print(f"\nğŸ“Š Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„:")
    print(f"  - Structured Pruning (Ø­Ø°Ù ÙÛŒÙ„ØªØ±): {'âœ“' if structured_pruning else 'âœ—'}")
    print(f"  - Unstructured Pruning (ØµÙØ± Ú©Ø±Ø¯Ù† ÙˆØ²Ù†): {'âœ“' if unstructured_pruning else 'âœ—'}")
    
    return structured_pruning, unstructured_pruning

structured, unstructured = analyze_pruning_type(sparse_state_dict)

print("\n" + "="*70)

if not structured:
    print("âš ï¸  Ø§ÛŒÙ† checkpoint Ø§Ø² Structured Pruning Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ø±Ø¯Ù‡!")
    print("âš ï¸  ÙÛŒÙ„ØªØ±Ù‡Ø§ Ø­Ø°Ù Ù†Ø´Ø¯Ù†ØŒ ÙÙ‚Ø· ÙˆØ²Ù†â€ŒÙ‡Ø§ sparse Ø´Ø¯Ù†.")
    print("\nğŸ’¡ Ø¯Ùˆ Ø±Ø§Ù‡â€ŒØ­Ù„ Ø¯Ø§Ø±ÛŒÙ…:")
    print("\n1ï¸âƒ£  Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø¹Ø§Ø¯ÛŒ (Ø¨Ø¯ÙˆÙ† pruned architecture):")
    print("   - Ù…Ø¯Ù„ ResNet50 Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯")
    print("   - ÙÙ‚Ø· ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ sparse Ù„ÙˆØ¯ Ù…ÛŒØ´Ù†")
    print("   - Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ù…Ø§Ø³Ú© Ù†ÛŒØ³Øª")
    print("\n2ï¸âƒ£  ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Structured Pruning:")
    print("   - ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨ÛŒØ´ØªØ± ØµÙØ± Ù‡Ø³ØªÙ† Ø±Ùˆ Ø­Ø°Ù Ú©Ù†ÛŒÙ…")
    print("   - Ù…Ø§Ø³Ú© Ø¨Ø³Ø§Ø²ÛŒÙ… Ùˆ Ù…Ø¯Ù„ pruned Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ…")
    
    response = input("\nâ“ Ú©Ø¯ÙˆÙ… Ø±ÙˆØ´ Ø±Ùˆ Ù…ÛŒØ®ÙˆØ§ÛŒØŸ (1 ÛŒØ§ 2): ").strip()
    
    if response == "1":
        print("\n" + "="*70)
        print("Ø±ÙˆØ´ 1: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø§ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Sparse")
        print("="*70)
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø¹Ø§Ø¯ÛŒ
        from torchvision.models import resnet50
        model = resnet50(pretrained=False)
        
        # ØªØºÛŒÛŒØ± fc Ø¨Ø±Ø§ÛŒ binary classification
        model.fc = nn.Linear(model.fc.in_features, 1)
        
        # Ù„ÙˆØ¯ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ sparse
        missing, unexpected = model.load_state_dict(sparse_state_dict, strict=False)
        print(f"âœ… ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ sparse Ù„ÙˆØ¯ Ø´Ø¯Ù†Ø¯")
        print(f"   - Missing keys: {len(missing)}")
        print(f"   - Unexpected keys: {len(unexpected)}")
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ sparsity
        total_params = sum(p.numel() for p in model.parameters())
        zero_params = sum((p == 0).sum().item() for p in model.parameters())
        print(f"\nğŸ“Š Ø¢Ù…Ø§Ø±:")
        print(f"   - ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§: {total_params:,}")
        print(f"   - Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ ØµÙØ±: {zero_params:,}")
        print(f"   - Sparsity: {zero_params/total_params*100:.2f}%")
        
        # ØªØ³Øª
        model.eval()
        with torch.no_grad():
            dummy_input = torch.randn(2, 3, 224, 224)
            output = model(dummy_input)
            print(f"\nâœ… ØªØ³Øª Ù…ÙˆÙÙ‚! Ø´Ú©Ù„ Ø®Ø±ÙˆØ¬ÛŒ: {output.shape}")
        
        # Ø°Ø®ÛŒØ±Ù‡
        save_path = '/kaggle/working/resnet50_sparse_weights.pt'
        torch.save({
            'model_state_dict': model.state_dict(),
            'total_params': total_params,
            'sparsity': zero_params/total_params,
            'model_type': 'standard_resnet50_with_sparse_weights'
        }, save_path)
        
        import os
        file_size_mb = os.path.getsize(save_path) / (1024 * 1024)
        print(f"\nâœ… Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø±: {save_path}")
        print(f"âœ… Ø­Ø¬Ù… ÙØ§ÛŒÙ„: {file_size_mb:.2f} MB")
        
    else:  # response == "2"
        print("\n" + "="*70)
        print("Ø±ÙˆØ´ 2: ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Structured Pruning")
        print("="*70)
        
        def convert_to_structured_pruning(state_dict, threshold=0.7):
            """
            ØªØ¨Ø¯ÛŒÙ„ unstructured Ø¨Ù‡ structured pruning
            ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ sparsity Ø¨ÛŒØ´ØªØ± Ø§Ø² threshold Ø¯Ø§Ø±Ù† Ø±Ùˆ Ø­Ø°Ù Ù…ÛŒÚ©Ù†ÛŒÙ…
            """
            masks = []
            pruned_filters = []
            original_filters = []
            
            resnet50_structure = {
                'layer1': {'blocks': 3, 'filters': [64, 64, 256]},
                'layer2': {'blocks': 4, 'filters': [128, 128, 512]},
                'layer3': {'blocks': 6, 'filters': [256, 256, 1024]},
                'layer4': {'blocks': 3, 'filters': [512, 512, 2048]}
            }
            
            print(f"\nğŸ” ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø§ threshold={threshold} (ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒÛŒ Ø¨Ø§ >{threshold*100}% sparsity Ø­Ø°Ù Ù…ÛŒØ´Ù†)")
            
            for layer_name in ['layer1', 'layer2', 'layer3', 'layer4']:
                num_blocks = resnet50_structure[layer_name]['blocks']
                standard_filters = resnet50_structure[layer_name]['filters']
                
                for block_idx in range(num_blocks):
                    for conv_idx in range(1, 4):
                        conv_key = f'{layer_name}.{block_idx}.conv{conv_idx}.weight'
                        
                        if conv_key in state_dict:
                            weight = state_dict[conv_key]
                            num_filters = weight.shape[0]
                            original_count = standard_filters[conv_idx - 1]
                            
                            # Ù…Ø­Ø§Ø³Ø¨Ù‡ sparsity Ù‡Ø± ÙÛŒÙ„ØªØ±
                            filter_sparsity = []
                            for i in range(num_filters):
                                filter_weights = weight[i].flatten()
                                zeros = (filter_weights == 0).sum().item()
                                sparsity = zeros / filter_weights.numel()
                                filter_sparsity.append(sparsity)
                            
                            # ØªØ¹ÛŒÛŒÙ† ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡ (sparsity < threshold)
                            active_filters = [i for i, s in enumerate(filter_sparsity) if s < threshold]
                            pruned_count = len(active_filters)
                            
                            # Ø³Ø§Ø®Øª Ù…Ø§Ø³Ú©
                            mask = torch.zeros(original_count)
                            for i in active_filters:
                                if i < original_count:
                                    mask[i] = 1
                            
                            masks.append(mask)
                            pruned_filters.append(pruned_count)
                            original_filters.append(original_count)
                            
                            avg_sparsity = sum(filter_sparsity) / len(filter_sparsity) * 100
                            print(f"  âœ“ {conv_key}: {pruned_count}/{original_count} ({avg_sparsity:.1f}% avg sparsity)")
            
            return masks, pruned_filters, original_filters
        
        masks, pruned_counts, original_counts = convert_to_structured_pruning(sparse_state_dict, threshold=0.7)
        
        print(f"\nâœ… ØªØ¹Ø¯Ø§Ø¯ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§: {len(masks)}")
        print(f"ğŸ“Š Ù†Ø±Ø® Ø­Ø°Ù Ú©Ù„ÛŒ: {(1 - sum(pruned_counts)/sum(original_counts))*100:.2f}%")
        
        # Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø§ Ø³Ø§Ø®Øª Ù…Ø¯Ù„ pruned...
        print("\nğŸ’¡ Ø­Ø§Ù„Ø§ Ù…ÛŒØªÙˆÙ†ÛŒ Ø§Ø² Ø§ÛŒÙ† Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª Ù…Ø¯Ù„ pruned Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒ")

else:
    print("âœ… Ø§ÛŒÙ† checkpoint Ø§Ø² Structured Pruning Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯Ù‡!")
    
    def extract_structured_masks(state_dict):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§ Ø§Ø² structured pruning"""
        masks = []
        pruned_filters = []
        original_filters = []
        
        resnet50_structure = {
            'layer1': {'blocks': 3, 'filters': [64, 64, 256]},
            'layer2': {'blocks': 4, 'filters': [128, 128, 512]},
            'layer3': {'blocks': 6, 'filters': [256, 256, 1024]},
            'layer4': {'blocks': 3, 'filters': [512, 512, 2048]}
        }
        
        for layer_name in ['layer1', 'layer2', 'layer3', 'layer4']:
            num_blocks = resnet50_structure[layer_name]['blocks']
            standard_filters = resnet50_structure[layer_name]['filters']
            
            for block_idx in range(num_blocks):
                for conv_idx in range(1, 4):
                    conv_key = f'{layer_name}.{block_idx}.conv{conv_idx}.weight'
                    
                    if conv_key in state_dict:
                        weight = state_dict[conv_key]
                        
                        # Ø´Ù…Ø§Ø±Ø´ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ non-zero
                        filter_norms = weight.view(weight.shape[0], -1).abs().sum(dim=1)
                        active_filters_indices = (filter_norms > 0).nonzero(as_tuple=True)[0]
                        pruned_count = len(active_filters_indices)
                        original_count = standard_filters[conv_idx - 1]
                        
                        # Ø³Ø§Ø®Øª Ù…Ø§Ø³Ú©
                        mask = torch.zeros(original_count)
                        mask[active_filters_indices] = 1
                        
                        masks.append(mask)
                        pruned_filters.append(pruned_count)
                        original_filters.append(original_count)
                        
                        print(f"  âœ“ {conv_key}: {pruned_count}/{original_count} ÙÛŒÙ„ØªØ±")
        
        return masks, pruned_filters, original_filters
    
    masks, pruned_counts, original_counts = extract_structured_masks(sparse_state_dict)
    
    # Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø§ Ø³Ø§Ø®Øª Ùˆ Ù„ÙˆØ¯ Ù…Ø¯Ù„...
    print(f"\nâœ… Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù†Ø¯!")

print("\n" + "="*70)
