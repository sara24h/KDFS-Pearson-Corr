import torch
import numpy as np
import matplotlib.pyplot as plt

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„
model_path = '/kaggle/input/fuzzy-ranked-based-ensemble/resnet50_pruned_model.pt'
checkpoint = torch.load(model_path, map_location='cpu')

print("="*100)
print("ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ù…Ø¯Ù„ ResNet50 Pruned")
print("="*100)

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ØµÙ„ÛŒ
state_dict = checkpoint['model_state_dict']
masks = checkpoint['masks']
pruned_counts = checkpoint['pruned_counts']
original_counts = checkpoint['original_counts']
total_params = checkpoint['total_params']
model_arch = checkpoint['model_architecture']

print(f"\nğŸ“Š Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù…Ø¯Ù„: {model_arch}")
print(f"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ (metadata): {total_params:,}")

print("\n" + "="*100)
print("ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§ÛŒ Pruning")
print("="*100)

if masks and len(masks) > 0:
    print(f"\nâœ“ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§: {len(masks)}")
    print(f"âœ“ ØªØ¹Ø¯Ø§Ø¯ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ pruned Ø´Ø¯Ù‡: {len(pruned_counts)}")
    print(f"âœ“ ØªØ¹Ø¯Ø§Ø¯ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ: {len(original_counts)}")
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
    total_pruned = sum(pruned_counts)
    total_original = sum(original_counts)
    overall_pruning_ratio = (total_pruned / total_original) * 100 if total_original > 0 else 0
    
    print(f"\nğŸ“‰ Ø¢Ù…Ø§Ø± Pruning Ú©Ù„ÛŒ:")
    print(f"   - Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ: {total_original:,}")
    print(f"   - Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡: {total_pruned:,}")
    print(f"   - Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡: {total_original - total_pruned:,}")
    print(f"   - Ù†Ø±Ø® Pruning: {overall_pruning_ratio:.2f}%")
    print(f"   - Ù†Ø±Ø® ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ: {(total_original / (total_original - total_pruned)):.2f}x")
    
    # ØªØ­Ù„ÛŒÙ„ Ø¬Ø²Ø¦ÛŒØ§Øª Ù‡Ø± Ù…Ø§Ø³Ú©
    print(f"\n{'#':<5} {'Layer Name':<50} {'Ø§ØµÙ„ÛŒ':<15} {'Ø­Ø°Ù Ø´Ø¯Ù‡':<15} {'Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡':<15} {'Ù†Ø±Ø® Pruning':<15}")
    print("-"*115)
    
    layer_names = [name for name in state_dict.keys() if 'weight' in name and 'bn' not in name and 'downsample' not in name]
    
    for idx, (mask, original, pruned) in enumerate(zip(masks, original_counts, pruned_counts)):
        remaining = original - pruned
        pruning_ratio = (pruned / original) * 100 if original > 0 else 0
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù†Ø§Ù… Ù„Ø§ÛŒÙ‡ Ù…Ø±ØªØ¨Ø·
        layer_name = f"Layer {idx+1}"
        if idx < len(layer_names):
            layer_name = layer_names[idx]
        
        print(f"{idx+1:<5} {layer_name:<50} {original:<15,} {pruned:<15,} {remaining:<15,} {pruning_ratio:<15.2f}%")
    
    # Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ø¨ÛŒØ´ØªØ±ÛŒÙ† pruning
    print("\n" + "="*100)
    print("ğŸ¯ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Pruning")
    print("="*100)
    
    pruning_ratios = [(i, (p/o)*100 if o > 0 else 0) for i, (p, o) in enumerate(zip(pruned_counts, original_counts))]
    top_pruned = sorted(pruning_ratios, key=lambda x: x[1], reverse=True)[:10]
    
    for rank, (idx, ratio) in enumerate(top_pruned, 1):
        layer_name = f"Layer {idx+1}"
        if idx < len(layer_names):
            layer_name = layer_names[idx]
        print(f"{rank}. {layer_name}: {ratio:.2f}% (Ø­Ø°Ù Ø´Ø¯Ù‡: {pruned_counts[idx]:,}/{original_counts[idx]:,})")
    
    # Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ú©Ù…ØªØ±ÛŒÙ† pruning
    print("\n" + "="*100)
    print("ğŸ¯ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ú©Ù…ØªØ±ÛŒÙ† Pruning")
    print("="*100)
    
    bottom_pruned = sorted(pruning_ratios, key=lambda x: x[1])[:10]
    
    for rank, (idx, ratio) in enumerate(bottom_pruned, 1):
        layer_name = f"Layer {idx+1}"
        if idx < len(layer_names):
            layer_name = layer_names[idx]
        print(f"{rank}. {layer_name}: {ratio:.2f}% (Ø­Ø°Ù Ø´Ø¯Ù‡: {pruned_counts[idx]:,}/{original_counts[idx]:,})")
    
    # Ø¢Ù…Ø§Ø± ØªÙˆØ²ÛŒØ¹ pruning
    print("\n" + "="*100)
    print("ğŸ“ˆ Ø¢Ù…Ø§Ø± ØªÙˆØ²ÛŒØ¹ Pruning")
    print("="*100)
    
    pruning_percentages = [(p/o)*100 if o > 0 else 0 for p, o in zip(pruned_counts, original_counts)]
    
    print(f"\nÙ…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù†Ø±Ø® pruning: {np.mean(pruning_percentages):.2f}%")
    print(f"Ù…ÛŒØ§Ù†Ù‡ Ù†Ø±Ø® pruning: {np.median(pruning_percentages):.2f}%")
    print(f"Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø±: {np.std(pruning_percentages):.2f}%")
    print(f"Ø­Ø¯Ø§Ù‚Ù„ Ù†Ø±Ø® pruning: {np.min(pruning_percentages):.2f}%")
    print(f"Ø­Ø¯Ø§Ú©Ø«Ø± Ù†Ø±Ø® pruning: {np.max(pruning_percentages):.2f}%")
    
    # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ø±Ø® pruning
    ranges = [
        (0, 10, "Ú©Ù… (0-10%)"),
        (10, 30, "Ù…ØªÙˆØ³Ø· (10-30%)"),
        (30, 50, "Ø²ÛŒØ§Ø¯ (30-50%)"),
        (50, 70, "Ø®ÛŒÙ„ÛŒ Ø²ÛŒØ§Ø¯ (50-70%)"),
        (70, 100, "Ø´Ø¯ÛŒØ¯ (70-100%)")
    ]
    
    print(f"\nğŸ“Š ØªÙˆØ²ÛŒØ¹ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ø±Ø® pruning:")
    for min_val, max_val, label in ranges:
        count = sum(1 for p in pruning_percentages if min_val <= p < max_val)
        percentage = (count / len(pruning_percentages)) * 100
        print(f"   {label}: {count} Ù„Ø§ÛŒÙ‡ ({percentage:.1f}%)")
    
    # ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§
    print("\n" + "="*100)
    print("ğŸ” ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø± Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§")
    print("="*100)
    
    print(f"\nÙ†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„:")
    for i in range(min(5, len(masks))):
        mask = masks[i]
        if isinstance(mask, (list, np.ndarray, torch.Tensor)):
            if isinstance(mask, torch.Tensor):
                mask_array = mask.cpu().numpy()
            else:
                mask_array = np.array(mask)
            
            unique_values = np.unique(mask_array)
            print(f"\nÙ…Ø§Ø³Ú© {i+1}:")
            print(f"   - Ø´Ú©Ù„: {mask_array.shape if hasattr(mask_array, 'shape') else len(mask_array)}")
            print(f"   - Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯: {unique_values}")
            print(f"   - ØªØ¹Ø¯Ø§Ø¯ 0Ù‡Ø§: {np.sum(mask_array == 0)}")
            print(f"   - ØªØ¹Ø¯Ø§Ø¯ 1Ù‡Ø§: {np.sum(mask_array == 1)}")

else:
    print("\nâš  Ù‡ÛŒÚ† Ù…Ø§Ø³Ú© ØµØ±ÛŒØ­ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")

print("\n" + "="*100)
print("ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø´Ø¯")
print("="*100)
