"""
Fuzzy Ensemble for Binary Classification - Standalone Version
Ø§ÛŒÙ† Ù†Ø³Ø®Ù‡ Ø´Ø§Ù…Ù„ ØªÙ…Ø§Ù… Ú©Ø¯Ù‡Ø§ÛŒ Ù„Ø§Ø²Ù… Ø§Ø³Øª Ùˆ Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ ÙØ§ÛŒÙ„ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ù†Ø¯Ø§Ø±Ø¯
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import numpy as np
import os
from tqdm import tqdm

# ============================================================
# Ø¨Ø®Ø´ 1: Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù…Ø¯Ù„ Pruned ResNet
# ============================================================

def get_preserved_filter_num(mask):
    return int(mask.sum())


class BasicBlock_pruned(nn.Module):
    expansion = 1

    def __init__(self, in_planes, planes, masks=[], stride=1):
        super().__init__()
        self.masks = masks

        preserved_filter_num1 = get_preserved_filter_num(masks[0])
        self.conv1 = nn.Conv2d(
            in_planes,
            preserved_filter_num1,
            kernel_size=3,
            stride=stride,
            padding=1,
            bias=False,
        )
        self.bn1 = nn.BatchNorm2d(preserved_filter_num1)
        preserved_filter_num2 = get_preserved_filter_num(masks[1])
        self.conv2 = nn.Conv2d(
            preserved_filter_num1,
            preserved_filter_num2,
            kernel_size=3,
            stride=1,
            padding=1,
            bias=False,
        )
        self.bn2 = nn.BatchNorm2d(preserved_filter_num2)

        self.downsample = nn.Sequential()
        if stride != 1 or in_planes != self.expansion * planes:
            self.downsample = nn.Sequential(
                nn.Conv2d(
                    in_planes,
                    self.expansion * planes,
                    kernel_size=1,
                    stride=stride,
                    bias=False,
                ),
                nn.BatchNorm2d(self.expansion * planes),
            )

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))

        shortcut_out = self.downsample(x)
        padded_out = torch.zeros_like(shortcut_out)

        idx = torch.nonzero(self.masks[1], as_tuple=False).squeeze(1)
        if idx.numel() > 0:
            temp_full = torch.zeros_like(padded_out)
            for i, ch_idx in enumerate(idx):
                temp_full[:, ch_idx, :, :] = out[:, i, :, :]
            padded_out = temp_full

        assert padded_out.shape == shortcut_out.shape, "wrong shape"

        padded_out += shortcut_out
        padded_out = F.relu(padded_out)
        return padded_out


class Bottleneck_pruned(nn.Module):
    expansion = 4

    def __init__(self, in_planes, planes, masks=[], stride=1):
        super().__init__()
        self.masks = masks

        preserved_filter_num1 = get_preserved_filter_num(masks[0])
        self.conv1 = nn.Conv2d(
            in_planes, preserved_filter_num1, kernel_size=1, bias=False
        )
        self.bn1 = nn.BatchNorm2d(preserved_filter_num1)
        preserved_filter_num2 = get_preserved_filter_num(masks[1])
        self.conv2 = nn.Conv2d(
            preserved_filter_num1,
            preserved_filter_num2,
            kernel_size=3,
            stride=stride,
            padding=1,
            bias=False,
        )
        self.bn2 = nn.BatchNorm2d(preserved_filter_num2)
        preserved_filter_num3 = get_preserved_filter_num(masks[2])
        self.conv3 = nn.Conv2d(
            preserved_filter_num2,
            preserved_filter_num3,
            kernel_size=1,
            bias=False,
        )
        self.bn3 = nn.BatchNorm2d(preserved_filter_num3)

        self.downsample = nn.Sequential()
        if stride != 1 or in_planes != self.expansion * planes:
            self.downsample = nn.Sequential(
                nn.Conv2d(
                    in_planes,
                    self.expansion * planes,
                    kernel_size=1,
                    stride=stride,
                    bias=False,
                ),
                nn.BatchNorm2d(self.expansion * planes),
            )

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = F.relu(self.bn2(self.conv2(out)))
        out = self.bn3(self.conv3(out))

        shortcut_out = self.downsample(x)
        padded_out = torch.zeros_like(shortcut_out)

        idx = torch.nonzero(self.masks[2], as_tuple=False).squeeze(1)
        if idx.numel() > 0:
            temp_full = torch.zeros_like(padded_out)
            for i, ch_idx in enumerate(idx):
                temp_full[:, ch_idx, :, :] = out[:, i, :, :]
            padded_out = temp_full

        assert padded_out.shape == shortcut_out.shape, "wrong shape"

        padded_out += shortcut_out
        padded_out = F.relu(padded_out)
        return padded_out


class ResNet_pruned(nn.Module):
    def __init__(self, block, num_blocks, masks=[], num_classes=1):
        super().__init__()
        self.in_planes = 64

        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        coef = 0
        if block == BasicBlock_pruned:
            coef = 2
        elif block == Bottleneck_pruned:
            coef = 3
        num = 0
        self.layer1 = self._make_layer(
            block,
            64,
            num_blocks[0],
            stride=1,
            masks=masks[0 : coef * num_blocks[0]],
        )
        num = num + coef * num_blocks[0]

        self.layer2 = self._make_layer(
            block,
            128,
            num_blocks[1],
            stride=2,
            masks=masks[num : num + coef * num_blocks[1]],
        )
        num = num + coef * num_blocks[1]

        self.layer3 = self._make_layer(
            block,
            256,
            num_blocks[2],
            stride=2,
            masks=masks[num : num + coef * num_blocks[2]],
        )
        num = num + coef * num_blocks[2]

        self.layer4 = self._make_layer(
            block,
            512,
            num_blocks[3],
            stride=2,
            masks=masks[num : num + coef * num_blocks[3]],
        )
        num = num + coef * num_blocks[3]

        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512 * block.expansion, num_classes)

    def _make_layer(self, block, planes, num_blocks, stride, masks=[]):
        strides = [stride] + [1] * (num_blocks - 1)
        layers = []

        coef = 0
        if block == BasicBlock_pruned:
            coef = 2
        elif block == Bottleneck_pruned:
            coef = 3

        for i, stride in enumerate(strides):
            layers.append(
                block(
                    self.in_planes,
                    planes,
                    masks[coef * i : coef * i + coef],
                    stride,
                )
            )
            self.in_planes = planes * block.expansion
        return nn.Sequential(*layers)

    def forward(self, x):
        feature_list = []

        out = F.relu(self.bn1(self.conv1(x)))
        out = self.maxpool(out)

        for block in self.layer1:
            out = block(out)
        feature_list.append(out)

        for block in self.layer2:
            out = block(out)
        feature_list.append(out)

        for block in self.layer3:
            out = block(out)
        feature_list.append(out)

        for block in self.layer4:
            out = block(out)
        feature_list.append(out)

        out = self.avgpool(out)
        out = out.view(out.size(0), -1)
        out = self.fc(out)
        return out, feature_list


def ResNet_50_pruned_hardfakevsreal(masks): 
    return ResNet_pruned(
        block=Bottleneck_pruned, num_blocks=[3, 4, 6, 3], masks=masks, num_classes=1
    )


# ============================================================
# Ø¨Ø®Ø´ 2: Dataset Ùˆ ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ
# ============================================================

class WildDeepfakeDataset(Dataset):
    """Ø¯ÛŒØªØ§Ø³Øª Ø³ÙØ§Ø±Ø´ÛŒ Ø¨Ø±Ø§ÛŒ Wild-Deepfake"""
    def __init__(self, real_path, fake_path, transform=None):
        self.transform = transform
        self.images = []
        self.labels = []
        
        # Ø®ÙˆØ§Ù†Ø¯Ù† ØªØµØ§ÙˆÛŒØ± real (label=0)
        if os.path.exists(real_path):
            real_files = [f for f in os.listdir(real_path) if f.endswith(('.jpg', '.jpeg', '.png'))]
            for fname in real_files:
                self.images.append(os.path.join(real_path, fname))
                self.labels.append(0)
        
        # Ø®ÙˆØ§Ù†Ø¯Ù† ØªØµØ§ÙˆÛŒØ± fake (label=1)
        if os.path.exists(fake_path):
            fake_files = [f for f in os.listdir(fake_path) if f.endswith(('.jpg', '.jpeg', '.png'))]
            for fname in fake_files:
                self.images.append(os.path.join(fake_path, fname))
                self.labels.append(1)
        
        print(f"ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ± Real: {len([l for l in self.labels if l==0])}")
        print(f"ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ± Fake: {len([l for l in self.labels if l==1])}")
        print(f"Ù…Ø¬Ù…ÙˆØ¹ ØªØµØ§ÙˆÛŒØ±: {len(self.images)}")
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        img_path = self.images[idx]
        label = self.labels[idx]
        
        try:
            image = Image.open(img_path).convert('RGB')
            if self.transform:
                image = self.transform(image)
            return image, label, img_path
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù„ÙˆØ¯ {img_path}: {e}")
            return torch.zeros(3, 224, 224), label, img_path


def load_pruned_model(checkpoint_path, device):
    """Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„ pruned Ø§Ø² checkpoint"""
    print(f"ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø§Ø²: {checkpoint_path}")
    
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    if isinstance(checkpoint, dict):
        print(f"âœ… Checkpoint Ø´Ø§Ù…Ù„ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ: {list(checkpoint.keys())}")
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ masks
        masks = checkpoint.get('masks', None)
        if masks is not None:
            masks_detached = [m.detach().clone() if m is not None else None for m in masks]
        else:
            masks_detached = None
            print("âš ï¸ Ù‡ÛŒÚ† mask Ø¯Ø± checkpoint ÛŒØ§ÙØª Ù†Ø´Ø¯")
        
        # Ø³Ø§Ø®Øª Ù…Ø¯Ù„ Ø¨Ø§ masks
        model = ResNet_50_pruned_hardfakevsreal(masks=masks_detached)
        
        # Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù† ÙˆØ²Ù†â€ŒÙ‡Ø§
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
            print("âœ… ÙˆØ²Ù†â€ŒÙ‡Ø§ Ø§Ø² 'model_state_dict' Ù„ÙˆØ¯ Ø´Ø¯Ù†Ø¯")
        elif 'state_dict' in checkpoint:
            model.load_state_dict(checkpoint['state_dict'])
            print("âœ… ÙˆØ²Ù†â€ŒÙ‡Ø§ Ø§Ø² 'state_dict' Ù„ÙˆØ¯ Ø´Ø¯Ù†Ø¯")
        else:
            model.load_state_dict(checkpoint)
            print("âœ… ÙˆØ²Ù†â€ŒÙ‡Ø§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø§Ø² checkpoint Ù„ÙˆØ¯ Ø´Ø¯Ù†Ø¯")
        
        total_params = sum(p.numel() for p in model.parameters())
        print(f"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§: {total_params:,}")
        
    else:
        raise ValueError("âŒ ÙØ±Ù…Øª checkpoint Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª!")
    
    model = model.to(device)
    model.eval()
    
    return model


def get_predictions(model, dataloader, device):
    """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§ÛŒÙ†Ø±ÛŒ"""
    all_probs = []
    all_labels = []
    
    model.eval()
    with torch.no_grad():
        for images, labels, _ in tqdm(dataloader, desc="Getting predictions"):
            images = images.to(device)
            
            # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ (Ù…Ø¯Ù„ ÛŒÚ© Ø®Ø±ÙˆØ¬ÛŒ Ùˆ feature map Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯)
            outputs, _ = model(images)
            
            # ØªØ¨Ø¯ÛŒÙ„ logits Ø¨Ù‡ Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª
            probs_fake = torch.sigmoid(outputs).squeeze()
            
            if probs_fake.dim() == 0:
                probs_fake = probs_fake.unsqueeze(0)
            
            probs_real = 1 - probs_fake
            probs_2class = torch.stack([probs_real, probs_fake], dim=1)
            
            all_probs.append(probs_2class.cpu().numpy())
            all_labels.append(labels.numpy())
    
    all_probs = np.vstack(all_probs)
    all_labels = np.concatenate(all_labels)
    
    return all_probs, all_labels


# ============================================================
# Ø¨Ø®Ø´ 3: ØªÙˆØ§Ø¨Ø¹ Fuzzy Ensemble
# ============================================================

def generateRank1(score, class_no=2):
    """ØªØ§Ø¨Ø¹ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ÙØ§Ø²ÛŒ Ø§ÙˆÙ„"""
    rank = np.zeros([class_no, 1])
    scores = score.reshape(-1, 1)
    
    for i in range(class_no):
        rank[i] = 1 - np.exp(-((scores[i] - 1) ** 2) / 2.0)
    
    return rank


def generateRank2(score, class_no=2):
    """ØªØ§Ø¨Ø¹ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ÙØ§Ø²ÛŒ Ø¯ÙˆÙ…"""
    rank = np.zeros([class_no, 1])
    scores = score.reshape(-1, 1)
    
    for i in range(class_no):
        rank[i] = 1 - np.tanh(((scores[i] - 1) ** 2) / 2)
    
    return rank


def fuzzy_ensemble_binary(res1, res2, labels, class_no=2):
    """ØªØ±Ú©ÛŒØ¨ ÙØ§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§ÛŒÙ†Ø±ÛŒ"""
    correct = 0
    predictions = []
    fusion_details = []
    
    for i in range(len(res1)):
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ØªØ¨Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ§Ø²ÛŒ
        rank1 = generateRank1(res1[i], class_no) * generateRank2(res1[i], class_no)
        rank2 = generateRank1(res2[i], class_no) * generateRank2(res2[i], class_no)
        
        # Ø¬Ù…Ø¹ Ø±ØªØ¨Ù‡â€ŒÙ‡Ø§
        rankSum = rank1 + rank2
        rankSum = np.array(rankSum)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø²Ø§Øª
        scoreSum = 1 - (res1[i] + res2[i]) / 2
        scoreSum = np.array(scoreSum).reshape(-1, 1)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ù†Ù‡Ø§ÛŒÛŒ ÙØ§Ø²ÛŒ
        fusedScore = (rankSum.T) * scoreSum
        
        # Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù„Ø§Ø³ Ø¨Ø§ Ú©Ù…ØªØ±ÛŒÙ† Ø±ØªØ¨Ù‡
        cls = np.argmin(rankSum)
        predictions.append(cls)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¬Ø²Ø¦ÛŒØ§Øª
        fusion_details.append({
            'sample_idx': i,
            'model1_probs': res1[i],
            'model2_probs': res2[i],
            'rank1': rank1.flatten(),
            'rank2': rank2.flatten(),
            'rankSum': rankSum.flatten(),
            'fusedScore': fusedScore.flatten(),
            'prediction': cls,
            'true_label': labels[i]
        })
        
        if cls < class_no and labels[i] == cls:
            correct += 1
    
    accuracy = correct / len(res1)
    
    return np.array(predictions), accuracy, fusion_details


def print_detailed_results(labels, predictions, model1_probs, model2_probs):
    """Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ ØªÙØµÛŒÙ„ÛŒ"""
    from sklearn.metrics import classification_report, confusion_matrix
    
    print("\n" + "="*70)
    print("ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ:")
    print("="*70)
    print(classification_report(labels, predictions, 
                                target_names=['Real', 'Fake'],
                                digits=4))
    
    print("\n" + "="*70)
    print("ğŸ“ˆ Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ:")
    print("="*70)
    cm = confusion_matrix(labels, predictions)
    print(f"\n{'':15} {'Predicted Real':>15} {'Predicted Fake':>15}")
    print(f"{'Actual Real':15} {cm[0,0]:>15} {cm[0,1]:>15}")
    print(f"{'Actual Fake':15} {cm[1,0]:>15} {cm[1,1]:>15}")
    
    print("\n" + "="*70)
    print("ğŸ“Š Ø¢Ù…Ø§Ø± ØªÙØµÛŒÙ„ÛŒ:")
    print("="*70)
    print(f"âœ… Real correctly classified: {cm[0,0]} / {cm[0,0] + cm[0,1]}")
    print(f"âŒ Real misclassified as Fake: {cm[0,1]} / {cm[0,0] + cm[0,1]}")
    print(f"âœ… Fake correctly classified: {cm[1,1]} / {cm[1,0] + cm[1,1]}")
    print(f"âŒ Fake misclassified as Real: {cm[1,0]} / {cm[1,0] + cm[1,1]}")
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ù‚Øª Ù‡Ø± Ù…Ø¯Ù„
    model1_preds = np.argmax(model1_probs, axis=1)
    model2_preds = np.argmax(model2_probs, axis=1)
    
    model1_acc = (model1_preds == labels).sum() / len(labels)
    model2_acc = (model2_preds == labels).sum() / len(labels)
    ensemble_acc = (predictions == labels).sum() / len(labels)
    
    print("\n" + "="*70)
    print("ğŸ”¬ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§:")
    print("="*70)
    print(f"Model 1 Accuracy: {model1_acc*100:.2f}%")
    print(f"Model 2 Accuracy: {model2_acc*100:.2f}%")
    print(f"Fuzzy Ensemble Accuracy: {ensemble_acc*100:.2f}%")
    improvement = (ensemble_acc - max(model1_acc, model2_acc))*100
    print(f"Ø¨Ù‡Ø¨ÙˆØ¯ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„: {improvement:+.2f}%")


# ============================================================
# Ø¨Ø®Ø´ 4: Main Function
# ============================================================

def main():
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª
    BATCH_SIZE = 32
    IMG_SIZE = 224
    NUM_WORKERS = 4
    
    # ØªÙ†Ø¸ÛŒÙ… Ø¯Ø³ØªÚ¯Ø§Ù‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ“± Ø¯Ø³ØªÚ¯Ø§Ù‡: {device}")
    
    if torch.cuda.is_available():
        print(f"ğŸš€ GPU: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ’¾ Ø­Ø§ÙØ¸Ù‡ GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    
    # ØªØ¹Ø±ÛŒÙ transforms
    val_transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.4414, 0.3448, 0.3159], 
                           std=[0.1854, 0.1623, 0.1562])
    ])
    
    # Ø§ÛŒØ¬Ø§Ø¯ dataset Ùˆ dataloader
    print("\nğŸ“‚ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯ÛŒØªØ§Ø³Øª...")
    test_dataset = WildDeepfakeDataset(
        real_path="/kaggle/input/wild-deepfake/test/real",
        fake_path="/kaggle/input/wild-deepfake/test/fake",
        transform=val_transform
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=NUM_WORKERS,
        pin_memory=True if torch.cuda.is_available() else False
    )
    
    # Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„â€ŒÙ‡Ø§
    print("\nğŸ”„ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§...")
    
    MODEL1_PATH = "/kaggle/input/10k_finetune_wd/pytorch/default/1/10k_final_pruned_finetuned_inference_ready (1).pt"
    MODEL2_PATH = "/kaggle/input/140k_finetuned_wd/pytorch/default/1/140k_final_pruned_finetuned_inference_ready (1).pt"
    
    model1 = load_pruned_model(MODEL1_PATH, device)
    print("âœ… Model 1 Ù„ÙˆØ¯ Ø´Ø¯\n")
    
    model2 = load_pruned_model(MODEL2_PATH, device)
    print("âœ… Model 2 Ù„ÙˆØ¯ Ø´Ø¯\n")
    
    # Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§
    print("ğŸ”® Model 1: Ø¯Ø± Ø­Ø§Ù„ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ...")
    predictions1, labels = get_predictions(model1, test_loader, device)
    
    print("ğŸ”® Model 2: Ø¯Ø± Ø­Ø§Ù„ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ...")
    predictions2, _ = get_predictions(model2, test_loader, device)
    
    print(f"\nâœ… Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
    print(f"   - ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§: {len(predictions1)}")
    print(f"   - Ø´Ú©Ù„ Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª: {predictions1.shape}")
    
    # ØªØ±Ú©ÛŒØ¨ ÙØ§Ø²ÛŒ
    print("\n" + "="*70)
    print("ğŸ¯ Ø¯Ø± Ø­Ø§Ù„ ØªØ±Ú©ÛŒØ¨ ÙØ§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§...")
    print("="*70)
    
    final_predictions, accuracy, fusion_details = fuzzy_ensemble_binary(
        predictions1, 
        predictions2, 
        labels,
        class_no=2
    )
    
    print(f"\nâœ… Ø¯Ù‚Øª ØªØ±Ú©ÛŒØ¨ ÙØ§Ø²ÛŒ: {accuracy * 100:.2f}%")
    print(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØµØ­ÛŒØ­: {int(accuracy * len(labels))}/{len(labels)}")
    
    # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ ØªÙØµÛŒÙ„ÛŒ
    print_detailed_results(labels, final_predictions, predictions1, predictions2)
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
    print("\nğŸ’¾ Ø¯Ø± Ø­Ø§Ù„ Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬...")
    
    results = {
        'final_predictions': final_predictions,
        'true_labels': labels,
        'accuracy': accuracy,
        'model1_probabilities': predictions1,
        'model2_probabilities': predictions2,
        'fusion_details': fusion_details[:100],
        'dataset_info': {
            'total_samples': len(labels),
            'real_samples': int((labels == 0).sum()),
            'fake_samples': int((labels == 1).sum())
        }
    }
    
    torch.save(results, 'fuzzy_ensemble_results.pt')
    print("âœ… Ù†ØªØ§ÛŒØ¬ Ø¯Ø± 'fuzzy_ensemble_results.pt' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
    
    # Ø°Ø®ÛŒØ±Ù‡ CSV
    import pandas as pd
    
    df_results = pd.DataFrame({
        'true_label': labels,
        'fuzzy_prediction': final_predictions,
        'model1_prob_real': predictions1[:, 0],
        'model1_prob_fake': predictions1[:, 1],
        'model2_prob_real': predictions2[:, 0],
        'model2_prob_fake': predictions2[:, 1],
        'is_correct': (final_predictions == labels).astype(int)
    })
    
    df_results.to_csv('fuzzy_ensemble_results.csv', index=False)
    print("âœ… Ù†ØªØ§ÛŒØ¬ Ø¯Ø± 'fuzzy_ensemble_results.csv' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
    
    print("\n" + "="*70)
    print("ğŸ‰ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!")
    print("="*70)


if __name__ == "__main__":
    main()
