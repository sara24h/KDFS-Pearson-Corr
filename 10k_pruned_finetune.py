import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import os
from tqdm import tqdm
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# âš ï¸ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ Ù…Ø¯Ù„ Ø¯Ø± Ù…Ø­ÛŒØ· Ø´Ù…Ø§ ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ Ùˆ Ù‚Ø§Ø¨Ù„ Import Ø§Ø³Øª
# Ø§ÛŒÙ† Ù…Ø¯Ù„ Ø§Ø² 'masks' Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø± Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
from model.pruned_model.ResNet_pruned import ResNet_50_pruned_hardfakevsreal 


# ==================== Û±. Ø¯ÛŒØªØ§Ø³Øª Ø³ÙØ§Ø±Ø´ÛŒ ====================
class DeepfakeDataset(Dataset):
    def __init__(self, real_dir, fake_dir, transform=None):
        self.image_paths = []
        self.labels = []
        self.transform = transform
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµØ§ÙˆÛŒØ± Real
        if os.path.exists(real_dir):
            for img_name in os.listdir(real_dir):
                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                    self.image_paths.append(os.path.join(real_dir, img_name))
                    self.labels.append(0)  # Real = 0
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµØ§ÙˆÛŒØ± Fake
        if os.path.exists(fake_dir):
            for img_name in os.listdir(fake_dir):
                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                    self.image_paths.append(os.path.join(fake_dir, img_name))
                    self.labels.append(1)  # Fake = 1

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        label = self.labels[idx]
        
        image = Image.open(img_path).convert('RGB')
        
        if self.transform:
            image = self.transform(image)
        
        return image, label

# ==================== Û². ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ Ùˆ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ====================
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø³ØªÚ¯Ø§Ù‡: {device}")

# Transformations (Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¢Ù…Ø§Ø± Ø¯ÛŒØªØ§Ø³Øª Ø´Ù…Ø§)
mean = [0.4414, 0.3448, 0.3159]
std = [0.1854, 0.1623, 0.1562]

train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=mean, std=std)
])

test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=mean, std=std)
])

# Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø¯ÛŒØªØ§Ø³Øª
BASE_DIR = "/kaggle/input/wild-deepfake"

train_dataset = DeepfakeDataset(
    real_dir=os.path.join(BASE_DIR, "train/real"), fake_dir=os.path.join(BASE_DIR, "train/fake"), transform=train_transform
)
valid_dataset = DeepfakeDataset(
    real_dir=os.path.join(BASE_DIR, "valid/real"), fake_dir=os.path.join(BASE_DIR, "valid/fake"), transform=test_transform
)
test_dataset = DeepfakeDataset(
    real_dir=os.path.join(BASE_DIR, "test/real"), fake_dir=os.path.join(BASE_DIR, "test/fake"), transform=test_transform
)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)
valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)

# ==================== Û³. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ù…Ø¯Ù„ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡ (Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡) ====================
print("\nğŸ”„ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ùˆ Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡...")

# âš ï¸ Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ú†Ú©â€ŒÙ¾ÙˆÛŒÙ†Øª Ø´Ù…Ø§
CHECKPOINT_PATH = '/kaggle/input/10k_final/pytorch/default/1/10k_final.pt' 

try:
    # 1. Ù„ÙˆØ¯ Ú†Ú©â€ŒÙ¾ÙˆÛŒÙ†Øª (Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ú©Ø§Ù…Ù„)
    checkpoint_loaded = torch.load(CHECKPOINT_PATH, map_location=device)
    
    # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØ²Ù†â€ŒÙ‡Ø§ Ùˆ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§ Ø¨Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ù…Ø­ØªÙ…Ù„
    
    # Ø§ÙˆÙ„ÙˆÛŒØª Ø§ÙˆÙ„: Ú©Ù„ÛŒØ¯ ØµØ­ÛŒØ­ Ú©Ù‡ Ø¯Ø± Ø¢Ø®Ø±ÛŒÙ† Ø®Ø±ÙˆØ¬ÛŒ Ø´Ù…Ø§ (model_state_dict) Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø´Ø¯
    if 'model_state_dict' in checkpoint_loaded:
        model_state_dict = checkpoint_loaded['model_state_dict']
    # Ø§ÙˆÙ„ÙˆÛŒØª Ø¯ÙˆÙ…: Ú©Ù„ÛŒØ¯ student (Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ú†Ú©â€ŒÙ¾ÙˆÛŒÙ†Øª Ø§Ø² Ù…Ø±Ø­Ù„Ù‡ KD/Pruning Ø¨Ø§Ø´Ø¯)
    elif 'student' in checkpoint_loaded:
        model_state_dict = checkpoint_loaded['student']
    else:
        raise KeyError("Ù‡ÛŒÚ† ÛŒÚ© Ø§Ø² Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ 'model_state_dict' ÛŒØ§ 'student' Ø¨Ø±Ø§ÛŒ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ù„ ÛŒØ§ÙØª Ù†Ø´Ø¯.")

    # Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§
    masks = checkpoint_loaded.get('masks')
    if masks is None:
        # Ø§Ú¯Ø± Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯Ù†Ø¯ØŒ Ù…Ø¯Ù„ Ø±Ø§ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ú©Ø±Ø¯
        raise KeyError("Ú©Ù„ÛŒØ¯ 'masks' Ø¯Ø± Ú†Ú©â€ŒÙ¾ÙˆÛŒÙ†Øª Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ù…Ø¯Ù„ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")

    # 3. Ø³Ø§Ø®Øª Ù…Ø¯Ù„ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§
    model = ResNet_50_pruned_hardfakevsreal(masks=masks)
    
    # 4. Ù„ÙˆØ¯ ÙˆØ²Ù†â€ŒÙ‡Ø§
    model.load_state_dict(model_state_dict)
    
    # 5. Ø§Ù†ØªÙ‚Ø§Ù„ Ù…Ø¯Ù„ Ø¨Ù‡ Ø¯Ø³ØªÚ¯Ø§Ù‡ (GPU/CPU)
    model = model.to(device)

    total_params = sum(p.numel() for p in model.parameters())
    print(f"âœ… Ù…Ø¯Ù„ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù„ÙˆØ¯ Ùˆ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ø´Ø¯! ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§: {total_params:,}")

except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù„ÙˆØ¯ Ùˆ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ù…Ø¯Ù„ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡: {e}")
    print(f"âš ï¸ Ø¬Ø²Ø¦ÛŒØ§Øª Ø®Ø·Ø§: {type(e).__name__}: {e}")
    # Ø®Ø±ÙˆØ¬ Ø§Ø² Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± Ù„ÙˆØ¯ Ù…Ø¯Ù„
    exit() 

# ==================== Û´. ØªÙ†Ø¸ÛŒÙ…Ø§Øª Fine-tuning ====================
criterion = nn.BCEWithLogitsLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)

num_epochs = 20
best_val_loss = float('inf')

# ==================== Ûµ. ØªÙˆØ§Ø¨Ø¹ Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ====================
def train_epoch(model, loader, criterion, optimizer, device):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    
    progress_bar = tqdm(loader, desc='Training', leave=False)
    for images, labels in progress_bar:
        images, labels = images.to(device), labels.to(device).float().unsqueeze(1)
        
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        predicted = (torch.sigmoid(outputs) > 0.5).float()
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        
        progress_bar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100.*correct/total:.2f}%'})
    
    return running_loss / len(loader), 100. * correct / total

def validate(model, loader, criterion, device):
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():
        progress_bar = tqdm(loader, desc='Validation', leave=False)
        for images, labels in progress_bar:
            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)
            
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item()
            predicted = (torch.sigmoid(outputs) > 0.5).float()
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
            progress_bar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100.*correct/total:.2f}%'})
    
    return running_loss / len(loader), 100. * correct / total

# ==================== Û¶. Ø§Ø¬Ø±Ø§ÛŒ Fine-tuning ====================
print("\nğŸš€ Ø´Ø±ÙˆØ¹ Fine-tuning Ù…Ø¯Ù„ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡...")
train_losses, val_losses = [], []
train_accs, val_accs = [], []

for epoch in range(num_epochs):
    print(f"\nğŸ“Š Epoch {epoch+1}/{num_epochs}")
    print("-" * 50)
    
    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)
    val_loss, val_acc = validate(model, valid_loader, criterion, device)
    
    train_losses.append(train_loss)
    val_losses.append(val_loss)
    train_accs.append(train_acc)
    val_accs.append(val_acc)
    
    print(f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%")
    print(f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%")
    
    scheduler.step(val_loss)
    
    # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ (ÙÙ‚Ø· state_dict)
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        # Ø°Ø®ÛŒØ±Ù‡ ÙˆØ²Ù†â€ŒÙ‡Ø§ Ùˆ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¢Ø³Ø§Ù† Ø¯Ø± Ø¢ÛŒÙ†Ø¯Ù‡
        torch.save({
            'model_state_dict': model.state_dict(),
            'masks': masks 
        }, 'best_finetuned_model_weights.pt')
        print("âœ… Ù…Ø¯Ù„ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØª Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯!")

# ==================== Û·. ØªØ³Øª Ù†Ù‡Ø§ÛŒÛŒ ====================
print("\nğŸ§ª Ø´Ø±ÙˆØ¹ ØªØ³Øª Ù†Ù‡Ø§ÛŒÛŒ...")

# Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø¨Ø§ Ø¨Ù‡ØªØ±ÛŒÙ† ÙˆØ²Ù†â€ŒÙ‡Ø§
try:
    model_test = ResNet_50_pruned_hardfakevsreal(masks=masks)
    best_weights = torch.load('best_finetuned_model_weights.pt', map_location=device)
    model_test.load_state_dict(best_weights['model_state_dict'])
    model_test = model_test.to(device)
    model_test.eval()
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ ØªØ³Øª: {e}. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡.")
    model_test = model # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ ÙØ¹Ù„ÛŒ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡
    model_test.eval()

all_preds = []
all_labels = []

with torch.no_grad():
    for images, labels in tqdm(test_loader, desc='Testing'):
        images = images.to(device)
        outputs = model_test(images)
        predicted = (torch.sigmoid(outputs) > 0.5).float().cpu().numpy()
        
        all_preds.extend(predicted.flatten())
        all_labels.extend(labels.numpy())

# Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§
accuracy = accuracy_score(all_labels, all_preds)
precision = precision_score(all_labels, all_preds)
recall = recall_score(all_labels, all_preds)
f1 = f1_score(all_labels, all_preds)
cm = confusion_matrix(all_labels, all_preds)

print("\n" + "="*60)
print("ğŸ“ˆ Ù†ØªØ§ÛŒØ¬ ØªØ³Øª Ù†Ù‡Ø§ÛŒÛŒ:")
print("="*60)
print(f"Accuracy:  {accuracy*100:.2f}%")
print(f"Precision: {precision*100:.2f}%")
print(f"Recall:    {recall*100:.2f}%")
print(f"F1-Score:  {f1*100:.2f}%")
print("\nConfusion Matrix:")
print(cm)

# Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# Loss curve
axes[0].plot(train_losses, label='Train Loss', marker='o')
axes[0].plot(val_losses, label='Val Loss', marker='s')
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('Loss')
axes[0].set_title('Training and Validation Loss')
axes[0].legend()
axes[0].grid(True)

# Accuracy curve
axes[1].plot(train_accs, label='Train Acc', marker='o')
axes[1].plot(val_accs, label='Val Acc', marker='s')
axes[1].set_xlabel('Epoch')
axes[1].set_ylabel('Accuracy (%)')
axes[1].set_title('Training and Validation Accuracy')
axes[1].legend()
axes[1].grid(True)

# Confusion matrix
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[2])
axes[2].set_xlabel('Predicted')
axes[2].set_ylabel('Actual')
axes[2].set_title('Confusion Matrix')
axes[2].set_xticklabels(['Real', 'Fake'])
axes[2].set_yticklabels(['Real', 'Fake'])

plt.tight_layout()
plt.savefig('training_results.png', dpi=300, bbox_inches='tight')
plt.show()

print("\nâœ… ÙØ±Ø¢ÛŒÙ†Ø¯ Fine-tuning Ùˆ ØªØ³Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯!")
print(f"ğŸ“ Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ (ÙˆØ²Ù†â€ŒÙ‡Ø§) Ø¯Ø± 'best_finetuned_model_weights.pt' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
print(f"ğŸ“Š Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ Ø¯Ø± 'training_results.png' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯")
