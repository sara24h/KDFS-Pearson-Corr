import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
import os
from tqdm import tqdm
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import json
from datetime import datetime
from model.pruned_model.ResNet_pruned import ResNet_50_pruned_hardfakevsreal

# ==================== ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ ====================
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Ø¯Ø³ØªÚ¯Ø§Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡: {DEVICE}")

EPOCHS = 5
BATCH_SIZE = 32
LEARNING_RATE = 0.0001
MODEL_PATH = "/kaggle/working/finetuned_pruned_model.pt"
INPUT_MODEL_PATH = '/kaggle/input/10k_pruned_model_resnet50/pytorch/default/1/resnet50_pruned_model_learnable_masks.pt'

DATA_PATHS = {
    "test": [
        "/kaggle/input/wild-deepfake/test/real",
        "/kaggle/input/wild-deepfake/test/fake",
    ],
    "train": [
        "/kaggle/input/wild-deepfake/train/real",
        "/kaggle/input/wild-deepfake/train/fake",
    ],
    "valid": [
        "/kaggle/input/wild-deepfake/valid/real",
        "/kaggle/input/wild-deepfake/valid/fake",
    ]
}

# ==================== ØªØ¹Ø±ÛŒÙ Dataset Custom ====================
class DeepfakeDataset(Dataset):
    def __init__(self, real_dir, fake_dir, transform=None):
        self.images = []
        self.labels = []
        self.transform = transform
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµØ§ÙˆÛŒØ± Real
        for img in os.listdir(real_dir):
            if img.lower().endswith(('.png', '.jpg', '.jpeg')):
                self.images.append(os.path.join(real_dir, img))
                self.labels.append(0)  # 0 = Real
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµØ§ÙˆÛŒØ± Fake
        for img in os.listdir(fake_dir):
            if img.lower().endswith(('.png', '.jpg', '.jpeg')):
                self.images.append(os.path.join(fake_dir, img))
                self.labels.append(1)  # 1 = Fake
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        try:
            img = Image.open(self.images[idx]).convert('RGB')
            if self.transform:
                img = self.transform(img)
            return img, torch.tensor(self.labels[idx], dtype=torch.float32)
        except:
            return None, None

# ==================== ØªØ­ÙˆÛŒÙ„ Dataset ====================
def collate_fn(batch):
    batch = [item for item in batch if item[0] is not None]
    if len(batch) == 0:
        return None, None
    imgs, labels = zip(*batch)
    return torch.stack(imgs), torch.stack(labels)

# ==================== ØªØ­Ø¶ÛŒØ± Ø¯Ø§Ø¯Ù‡ ====================
transform_train = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225])
])

transform_test = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225])
])

print("\nğŸ“Š Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯ÛŒØªØ§Ø³Øª...")

train_dataset = DeepfakeDataset(
    DATA_PATHS["train"][0], 
    DATA_PATHS["train"][1], 
    transform_train
)
train_loader = DataLoader(
    train_dataset, 
    batch_size=BATCH_SIZE, 
    shuffle=True,
    collate_fn=collate_fn,
    num_workers=2
)

valid_dataset = DeepfakeDataset(
    DATA_PATHS["valid"][0], 
    DATA_PATHS["valid"][1], 
    transform_test
)
valid_loader = DataLoader(
    valid_dataset, 
    batch_size=BATCH_SIZE, 
    shuffle=False,
    collate_fn=collate_fn,
    num_workers=2
)

test_dataset = DeepfakeDataset(
    DATA_PATHS["test"][0], 
    DATA_PATHS["test"][1], 
    transform_test
)
test_loader = DataLoader(
    test_dataset, 
    batch_size=BATCH_SIZE, 
    shuffle=False,
    collate_fn=collate_fn,
    num_workers=2
)

print(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´: {len(train_dataset)}")
print(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ: {len(valid_dataset)}")
print(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª: {len(test_dataset)}")

# ==================== Ù„ÙˆØ¯ Ù…Ø¯Ù„ ====================
print("\nğŸ”§ Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡...")

try:
    # Ù„ÙˆØ¯ Ú†Ú©â€ŒÙ¾ÙˆÛŒÙ†Øª Ú©Ø§Ù…Ù„ ÙˆØ±ÙˆØ¯ÛŒ
    checkpoint_loaded = torch.load(INPUT_MODEL_PATH, map_location=DEVICE)
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
    model_state_dict = checkpoint_loaded['model_state_dict']
    masks = checkpoint_loaded['masks']
    
    # Ø³Ø§Ø®Øª Ù…Ø¯Ù„ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§
    model = ResNet_50_pruned_hardfakevsreal(masks=masks)
    
    # Ù„ÙˆØ¯ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡
    model.load_state_dict(model_state_dict)
    
    model = model.to(DEVICE)
    
    total_params = sum(p.numel() for p in model.parameters())
    print("âœ… Ù…Ø¯Ù„ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ùˆ Ù„ÙˆØ¯ Ø´Ø¯!")
    print(f"ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§: {total_params:,}")
    
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù„ÙˆØ¯ Ù…Ø¯Ù„: {e}")
    raise

# ==================== ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¢Ù…ÙˆØ²Ø´ ====================
criterion = nn.BCEWithLogitsLoss()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)

# ==================== ØªØ§Ø¨Ø¹ Ø¢Ù…ÙˆØ²Ø´ ====================
def train_epoch(model, train_loader, criterion, optimizer, epoch, device):
    model.train()
    total_loss = 0
    correct = 0
    total = 0
    
    progress_bar = tqdm(train_loader, desc=f"Ø¢Ù…ÙˆØ²Ø´ Epoch {epoch+1}/{EPOCHS}", 
                       unit='batch', colour='green')
    
    for batch_idx, (images, labels) in enumerate(progress_bar):
        if images is None:
            continue
            
        images, labels = images.to(device), labels.to(device).unsqueeze(1)
        
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        predictions = (torch.sigmoid(outputs) > 0.5).float()
        correct += (predictions == labels).sum().item()
        total += labels.size(0)
        
        accuracy = (correct / total) * 100 if total > 0 else 0
        progress_bar.set_postfix({
            'loss': f'{loss.item():.4f}',
            'accuracy': f'{accuracy:.2f}%'
        })
    
    avg_loss = total_loss / len(train_loader) if len(train_loader) > 0 else 0
    avg_accuracy = (correct / total) * 100 if total > 0 else 0
    
    return avg_loss, avg_accuracy

# ==================== ØªØ§Ø¨Ø¹ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ ====================
def validate(model, val_loader, criterion, device, phase="Validation"):
    model.eval()
    total_loss = 0
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        progress_bar = tqdm(val_loader, desc=f"{phase}", 
                           unit='batch', colour='blue')
        
        for images, labels in progress_bar:
            if images is None:
                continue
                
            images, labels = images.to(device), labels.to(device).unsqueeze(1)
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            total_loss += loss.item()
            predictions = (torch.sigmoid(outputs) > 0.5).float()
            
            all_preds.extend(predictions.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    avg_loss = total_loss / len(val_loader) if len(val_loader) > 0 else 0
    accuracy = accuracy_score(all_labels, all_preds) * 100 if len(all_labels) > 0 else 0
    precision = precision_score(all_labels, all_preds, zero_division=0) * 100
    recall = recall_score(all_labels, all_preds, zero_division=0) * 100
    f1 = f1_score(all_labels, all_preds, zero_division=0) * 100
    
    return avg_loss, accuracy, precision, recall, f1

# ==================== Ø­Ù„Ù‚Ù‡ Ø¢Ù…ÙˆØ²Ø´ ====================
print("\nğŸš€ Ø´Ø±ÙˆØ¹ ÙØ§ÛŒÙ†â€ŒØªÛŒÙˆÙ† Ù…Ø¯Ù„...")
print("=" * 80)

history = {
    'train_loss': [],
    'train_acc': [],
    'val_loss': [],
    'val_acc': [],
    'val_precision': [],
    'val_recall': [],
    'val_f1': []
}

best_accuracy = 0

for epoch in range(EPOCHS):
    print(f"\nğŸ“… Epoch {epoch+1}/{EPOCHS}")
    print("-" * 80)
    
    # Ø¢Ù…ÙˆØ²Ø´
    train_loss, train_acc = train_epoch(model, train_loader, criterion, 
                                        optimizer, epoch, DEVICE)
    
    # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
    val_loss, val_acc, val_prec, val_recall, val_f1 = validate(
        model, valid_loader, criterion, DEVICE, "Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ"
    )
    
    # Ø°Ø®ÛŒØ±Ù‡â€ŒÛŒ Ù†ØªØ§ÛŒØ¬
    history['train_loss'].append(train_loss)
    history['train_acc'].append(train_acc)
    history['val_loss'].append(val_loss)
    history['val_acc'].append(val_acc)
    history['val_precision'].append(val_prec)
    history['val_recall'].append(val_recall)
    history['val_f1'].append(val_f1)
    
    print(f"âœ… Ø¢Ù…ÙˆØ²Ø´ - Loss: {train_loss:.4f} | Ø¯Ù‚Øª: {train_acc:.2f}%")
    print(f"âœ… Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ - Loss: {val_loss:.4f} | Ø¯Ù‚Øª: {val_acc:.2f}%")
    print(f"   Precision: {val_prec:.2f}% | Recall: {val_recall:.2f}% | F1: {val_f1:.2f}%")
    
    scheduler.step()
    
    # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
    if val_acc > best_accuracy:
        best_accuracy = val_acc
        checkpoint_to_save = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'masks': masks,
            'accuracy': val_acc,
            'model_architecture': 'ResNet_50_pruned_hardfakevsreal'
        }
        torch.save(checkpoint_to_save, MODEL_PATH)
        print(f"ğŸ’¾ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯! (Ø¯Ù‚Øª: {best_accuracy:.2f}%)")

# ==================== ØªØ³Øª Ù†Ù‡Ø§ÛŒÛŒ ====================
print("\n" + "=" * 80)
print("ğŸ§ª Ø´Ø±ÙˆØ¹ ØªØ³Øª Ù†Ù‡Ø§ÛŒÛŒ...")
print("=" * 80)

# Ù„ÙˆØ¯ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
model.load_state_dict(checkpoint['model_state_dict'])

test_loss, test_acc, test_prec, test_recall, test_f1 = validate(
    model, test_loader, criterion, DEVICE, "ØªØ³Øª Ù†Ù‡Ø§ÛŒÛŒ"
)

print("\n" + "=" * 80)
print("ğŸ“Š Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ:")
print("=" * 80)
print(f"âœ… Ø¯Ù‚Øª Ú©Ù„ÛŒ: {test_acc:.2f}%")
print(f"âœ… Precision: {test_prec:.2f}%")
print(f"âœ… Recall: {test_recall:.2f}%")
print(f"âœ… F1-Score: {test_f1:.2f}%")
print(f"âœ… Loss: {test_loss:.4f}")

# ==================== Ø°Ø®ÛŒØ±Ù‡â€ŒÛŒ Ú¯Ø²Ø§Ø±Ø´ ====================
report = {
    'timestamp': datetime.now().isoformat(),
    'model_path': MODEL_PATH,
    'best_epoch_accuracy': best_accuracy,
    'test_results': {
        'accuracy': test_acc,
        'precision': test_prec,
        'recall': test_recall,
        'f1_score': test_f1,
        'loss': test_loss
    },
    'hyperparameters': {
        'epochs': EPOCHS,
        'batch_size': BATCH_SIZE,
        'learning_rate': LEARNING_RATE
    },
    'training_history': history
}

with open('/kaggle/working/training_report.json', 'w') as f:
    json.dump(report, f, indent=2)

print("\nğŸ’¾ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯!")
print(f"ğŸ“ Ù…Ø¯Ù„: {MODEL_PATH}")
print(f"ğŸ“ Ú¯Ø²Ø§Ø±Ø´: /kaggle/working/training_report.json")
