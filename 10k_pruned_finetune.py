import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import os
from tqdm import tqdm
import numpy as np
from model.pruned_model.ResNet_pruned import ResNet_50_pruned_hardfakevsreal

# ============================================================
# 1. ØªØ¹Ø±ÛŒÙ Dataset Ø³ÙØ§Ø±Ø´ÛŒ
# ============================================================
class WildDeepfakeDataset(Dataset):
    def __init__(self, real_path, fake_path, transform=None):
        self.transform = transform
        self.images = []
        self.labels = []
        
        # Ù„ÙˆØ¯ ØªØµØ§ÙˆÛŒØ± Real (label = 0)
        if os.path.exists(real_path):
            real_files = [f for f in os.listdir(real_path) if f.endswith(('.jpg', '.jpeg', '.png'))]
            for fname in real_files:
                self.images.append(os.path.join(real_path, fname))
                self.labels.append(0)
        
        # Ù„ÙˆØ¯ ØªØµØ§ÙˆÛŒØ± Fake (label = 1)
        if os.path.exists(fake_path):
            fake_files = [f for f in os.listdir(fake_path) if f.endswith(('.jpg', '.jpeg', '.png'))]
            for fname in fake_files:
                self.images.append(os.path.join(fake_path, fname))
                self.labels.append(1)
        
        print(f"ðŸ“Š Dataset loaded: {len(self.images)} images ({sum(1 for l in self.labels if l==0)} real, {sum(1 for l in self.labels if l==1)} fake)")
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        img_path = self.images[idx]
        label = self.labels[idx]
        
        try:
            img = Image.open(img_path).convert('RGB')
            if self.transform:
                img = self.transform(img)
            return img, torch.tensor(label, dtype=torch.float32)
        except Exception as e:
            print(f"âŒ Error loading {img_path}: {e}")
            # Ø¨Ø§Ø²Ú¯Ø´Øª ÛŒÚ© ØªØµÙˆÛŒØ± Ø®Ø§Ù„ÛŒ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§
            return torch.zeros(3, 224, 224), torch.tensor(label, dtype=torch.float32)

# ============================================================
# 2. ØªØ¹Ø±ÛŒÙ Transforms
# ============================================================
train_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[[0.4414, 0.3448, 0.3159], std=[0.1854, 0.1623, 0.1562])
])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[[0.4414, 0.3448, 0.3159], std=[0.1854, 0.1623, 0.1562])
])

# ============================================================
# 3. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ DataLoaders
# ============================================================
def create_dataloaders(batch_size=32, num_workers=4):
    # Train dataset
    train_dataset = WildDeepfakeDataset(
        real_path="/kaggle/input/wild-deepfake/train/real",
        fake_path="/kaggle/input/wild-deepfake/train/fake",
        transform=train_transform
    )
    
    # Validation dataset
    val_dataset = WildDeepfakeDataset(
        real_path="/kaggle/input/wild-deepfake/valid/real",
        fake_path="/kaggle/input/wild-deepfake/valid/fake",
        transform=val_transform
    )
    
    # Test dataset
    test_dataset = WildDeepfakeDataset(
        real_path="/kaggle/input/wild-deepfake/test/real",
        fake_path="/kaggle/input/wild-deepfake/test/fake",
        transform=val_transform
    )
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, 
                            num_workers=num_workers, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, 
                          num_workers=num_workers, pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, 
                           num_workers=num_workers, pin_memory=True)
    
    return train_loader, val_loader, test_loader

# ============================================================
# 4. ØªØ§Ø¨Ø¹ Ø¢Ù…ÙˆØ²Ø´
# ============================================================
def train_epoch(model, loader, criterion, optimizer, device):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    
    pbar = tqdm(loader, desc="Training")
    for inputs, labels in pbar:
        inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1)
        
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        preds = (torch.sigmoid(outputs) > 0.5).float()
        correct += (preds == labels).sum().item()
        total += labels.size(0)
        
        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100.*correct/total:.2f}%'})
    
    epoch_loss = running_loss / len(loader)
    epoch_acc = 100. * correct / total
    return epoch_loss, epoch_acc

# ============================================================
# 5. ØªØ§Ø¨Ø¹ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
# ============================================================
def validate(model, loader, criterion, device):
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for inputs, labels in tqdm(loader, desc="Validation"):
            inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1)
            
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item()
            preds = (torch.sigmoid(outputs) > 0.5).float()
            correct += (preds == labels).sum().item()
            total += labels.size(0)
    
    epoch_loss = running_loss / len(loader)
    epoch_acc = 100. * correct / total
    return epoch_loss, epoch_acc

# ============================================================
# 6. Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Fine-tuning
# ============================================================
def main():
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª
    DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    BATCH_SIZE = 32
    NUM_EPOCHS = 20
    LEARNING_RATE = 0.001
    WEIGHT_DECAY = 1e-4
    
    print("="*70)
    print("ðŸš€ Ø´Ø±ÙˆØ¹ Fine-tuning Ù…Ø¯Ù„ Pruned ResNet50")
    print("="*70)
    
    # Ù„ÙˆØ¯ Ù…Ø¯Ù„
    print("\nðŸ“¦ Ù„ÙˆØ¯ Ù…Ø¯Ù„ Pruned...")
    input_model_path = '/kaggle/input/10k_final/pytorch/default/1/10k_final.pt'
    checkpoint = torch.load(input_model_path, map_location=DEVICE)
    
    model = ResNet_50_pruned_hardfakevsreal(masks=checkpoint['masks'])
    model.load_state_dict(checkpoint['model_state_dict'])
    model = model.to(DEVICE)
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"âœ… Ù…Ø¯Ù„ Ù„ÙˆØ¯ Ø´Ø¯ - ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§: {total_params:,}")
    
    # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    print("\nðŸ“Š Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ DataLoaders...")
    train_loader, val_loader, test_loader = create_dataloaders(
        batch_size=BATCH_SIZE, 
        num_workers=4
    )
    
    # ØªØ¹Ø±ÛŒÙ Loss Ùˆ Optimizer
    criterion = nn.BCEWithLogitsLoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, 
                                                     patience=3, verbose=True)
    
    # Ø¢Ù…ÙˆØ²Ø´
    print("\n" + "="*70)
    print("ðŸŽ“ Ø´Ø±ÙˆØ¹ Ø¢Ù…ÙˆØ²Ø´")
    print("="*70)
    
    best_val_acc = 0.0
    best_model_path = '/kaggle/working/best_pruned_finetuned.pt'
    
    for epoch in range(NUM_EPOCHS):
        print(f"\nðŸ“ Epoch {epoch+1}/{NUM_EPOCHS}")
        print("-" * 70)
        
        # Ø¢Ù…ÙˆØ²Ø´
        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, DEVICE)
        print(f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%")
        
        # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
        val_loss, val_acc = validate(model, val_loader, criterion, DEVICE)
        print(f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%")
        
        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Learning Rate
        scheduler.step(val_acc)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'masks': checkpoint['masks'],
                'optimizer_state_dict': optimizer.state_dict(),
                'val_acc': val_acc,
                'total_params': total_params
            }, best_model_path)
            print(f"ðŸ’¾ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ (Val Acc: {val_acc:.2f}%)")
    
    # ØªØ³Øª Ù†Ù‡Ø§ÛŒÛŒ
    print("\n" + "="*70)
    print("ðŸ§ª ØªØ³Øª Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„")
    print("="*70)
    
    best_checkpoint = torch.load(best_model_path)
    model.load_state_dict(best_checkpoint['model_state_dict'])
    
    test_loss, test_acc = validate(model, test_loader, criterion, DEVICE)
    print(f"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%")
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ
    final_model_path = '/kaggle/working/final_pruned_finetuned.pt'
    torch.save({
        'model_state_dict': model.state_dict(),
        'masks': checkpoint['masks'],
        'test_acc': test_acc,
        'best_val_acc': best_val_acc,
        'total_params': total_params,
        'model_architecture': 'ResNet_50_pruned_hardfakevsreal'
    }, final_model_path)
    
    print(f"\nâœ… Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ Ø¯Ø± {final_model_path} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
    print(f"ðŸ“Š Ø¨Ù‡ØªØ±ÛŒÙ† Ø¯Ù‚Øª Validation: {best_val_acc:.2f}%")
    print(f"ðŸ“Š Ø¯Ù‚Øª Test: {test_acc:.2f}%")

if __name__ == "__main__":
    main()
