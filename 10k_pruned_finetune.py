import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import os
from tqdm import tqdm
import numpy as np
from model.pruned_model.ResNet_pruned import ResNet_50_pruned_hardfakevsreal # ÛŒØ§ Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø´Ù…Ø§

# ============================================================
# 1. ØªØ¹Ø±ÛŒÙ Dataset Ø³ÙØ§Ø±Ø´ÛŒ
# ============================================================
class WildDeepfakeDataset(Dataset):
    def __init__(self, real_path, fake_path, transform=None):
        self.transform = transform
        self.images = []
        self.labels = []
        
        # Ù„ÙˆØ¯ ØªØµØ§ÙˆÛŒØ± Real (label = 0)
        if os.path.exists(real_path):
            real_files = [f for f in os.listdir(real_path) if f.endswith(('.jpg', '.jpeg', '.png'))]
            for fname in real_files:
                self.images.append(os.path.join(real_path, fname))
                self.labels.append(0)
        
        # Ù„ÙˆØ¯ ØªØµØ§ÙˆÛŒØ± Fake (label = 1)
        if os.path.exists(fake_path):
            fake_files = [f for f in os.listdir(fake_path) if f.endswith(('.jpg', '.jpeg', '.png'))]
            for fname in fake_files:
                self.images.append(os.path.join(fake_path, fname))
                self.labels.append(1)
        
        print(f"ğŸ“Š Dataset loaded: {len(self.images)} images ({sum(1 for l in self.labels if l==0)} real, {sum(1 for l in self.labels if l==1)} fake)")
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        img_path = self.images[idx]
        label = self.labels[idx]
        
        try:
            img = Image.open(img_path).convert('RGB')
            if self.transform:
                img = self.transform(img)
            # Ø¨Ø±Ø§ÛŒ BCEWithLogitsLoss Ø¨Ø§ num_classes=1ØŒ Ù„ÛŒØ¨Ù„ Ø¨Ø§ÛŒØ¯ float Ø¨Ø§Ø´Ø¯
            return img, torch.tensor(label, dtype=torch.float32)
        except Exception as e:
            print(f"âŒ Error loading {img_path}: {e}")
            return torch.zeros(3, 224, 224), torch.tensor(label, dtype=torch.float32)

# ============================================================
# 2. ØªØ¹Ø±ÛŒÙ Transforms
# ============================================================
train_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# ============================================================
# 3. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ DataLoaders
# ============================================================
def create_dataloaders(batch_size=32, num_workers=4):
    train_dataset = WildDeepfakeDataset(
        real_path="/kaggle/input/wild-deepfake/train/real",
        fake_path="/kaggle/input/wild-deepfake/train/fake",
        transform=train_transform
    )
    
    val_dataset = WildDeepfakeDataset(
        real_path="/kaggle/input/wild-deepfake/valid/real",
        fake_path="/kaggle/input/wild-deepfake/valid/fake",
        transform=val_transform
    )
    
    test_dataset = WildDeepfakeDataset(
        real_path="/kaggle/input/wild-deepfake/test/real",
        fake_path="/kaggle/input/wild-deepfake/test/fake",
        transform=val_transform
    )
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, 
                            num_workers=num_workers, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, 
                          num_workers=num_workers, pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, 
                           num_workers=num_workers, pin_memory=True)
    
    return train_loader, val_loader, test_loader

# ============================================================
# 4. ØªØ§Ø¨Ø¹ Ø¢Ù…ÙˆØ²Ø´
# ============================================================
def train_epoch(model, loader, criterion, optimizer, device, accumulation_steps=1):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    
    optimizer.zero_grad()
    pbar = tqdm(loader, desc="Training")
    
    for batch_idx, (inputs, labels) in enumerate(pbar):
        inputs, labels = inputs.to(device), labels.to(device) # Ø¨Ø¯ÙˆÙ† unsqueeze

        # ÙÙ‚Ø· Ø®Ø±ÙˆØ¬ÛŒ Ø§ÙˆÙ„ Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ú¯ÛŒØ±
        outputs, _ = model(inputs) # <--- ØªØºÛŒÛŒØ± Ø§ÛŒÙ†Ø¬Ø§

        # **Ø±Ø§Ù‡â€ŒØ­Ù„ Ú©Ù„ÛŒØ¯ÛŒ: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² autocast Ø¨Ø±Ø§ÛŒ mixed precision**
        with torch.cuda.amp.autocast(enabled=True):
            loss = criterion(outputs, labels)
            loss = loss / accumulation_steps
        
        # Backward Ø¨Ø§ scaler
        loss.backward()
        
        # Gradient accumulation
        if (batch_idx + 1) % accumulation_steps == 0:
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            optimizer.zero_grad()
        
        running_loss += loss.item() * accumulation_steps
        with torch.no_grad():
            preds = (torch.sigmoid(outputs) > 0.5).float()
            correct += (preds == labels).sum().item()
            total += labels.size(0)
        
        pbar.set_postfix({
            'loss': f'{loss.item() * accumulation_steps:.4f}', 
            'acc': f'{100.*correct/total:.2f}%'
        })
    
    epoch_loss = running_loss / len(loader)
    epoch_acc = 100. * correct / total
    return epoch_loss, epoch_acc

# ============================================================
# 5. ØªØ§Ø¨Ø¹ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
# ============================================================
@torch.no_grad()
def validate(model, loader, criterion, device):
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    
    for inputs, labels in tqdm(loader, desc="Validation"):
        inputs, labels = inputs.to(device), labels.to(device) # Ø¨Ø¯ÙˆÙ† unsqueeze

        # ÙÙ‚Ø· Ø®Ø±ÙˆØ¬ÛŒ Ø§ÙˆÙ„ Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ú¯ÛŒØ±
        outputs, _ = model(inputs) # <--- ØªØºÛŒÛŒØ± Ø§ÛŒÙ†Ø¬Ø§
        
        with torch.cuda.amp.autocast(enabled=True):
            loss = criterion(outputs, labels)
        
        running_loss += loss.item()
        preds = (torch.sigmoid(outputs) > 0.5).float()
        correct += (preds == labels).sum().item()
        total += labels.size(0)
    
    epoch_loss = running_loss / len(loader)
    epoch_acc = 100. * correct / total
    return epoch_loss, epoch_acc

# ============================================================
# 6. Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Fine-tuning
# ============================================================
def main():
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª
    DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    BATCH_SIZE = 16  # Ú©Ø§Ù‡Ø´ batch size Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ø´Ú©Ù„ memory
    NUM_EPOCHS = 10
    LEARNING_RATE = 0.0001  # Ú©Ø§Ù‡Ø´ LR Ø¨Ø±Ø§ÛŒ fine-tuning Ø±ÙˆÛŒ Ù…Ø¯Ù„ pruned
    WEIGHT_DECAY = 1e-4
    ACCUMULATION_STEPS = 2  # Ø¨Ø±Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ batch size Ø¨Ø²Ø±Ú¯ØªØ±
    
    print("="*70)
    print("ğŸš€ Ø´Ø±ÙˆØ¹ Fine-tuning Ù…Ø¯Ù„ Pruned ResNet50")
    print("="*70)
    
    # Ù„ÙˆØ¯ Ù…Ø¯Ù„
    print("\nğŸ“¦ Ù„ÙˆØ¯ Ù…Ø¯Ù„ Pruned...")
    input_model_path = '/kaggle/input/m/saraaskari/10k_final/pytorch/default/1/10k_final.pt'
    checkpoint = torch.load(input_model_path, map_location=DEVICE)
    
    # Ø³Ø§Ø®Øª Ù…Ø¯Ù„ Ø¨Ø§ detach Ú©Ø±Ø¯Ù† masks
    masks_detached = [m.detach().clone() if m is not None else None for m in checkpoint['masks']]
    
    model = ResNet_50_pruned_hardfakevsreal(masks=masks_detached)
    model.load_state_dict(checkpoint['model_state_dict'])
    
    model = model.to(DEVICE)
    
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"âœ… Ù…Ø¯Ù„ Ù„ÙˆØ¯ Ø´Ø¯")
    print(f"   - ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§: {total_params:,}")
    print(f"   - ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ø¢Ù…ÙˆØ²Ø´: {trainable_params:,}")
    
    # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    print("\nğŸ“Š Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ DataLoaders...")
    train_loader, val_loader, test_loader = create_dataloaders(
        batch_size=BATCH_SIZE, 
        num_workers=2  # Ú©Ø§Ù‡Ø´ Ø¨Ø±Ø§ÛŒ stability
    )
    
    # ØªØ¹Ø±ÛŒÙ Loss Ùˆ Optimizer
    # Ú†ÙˆÙ† num_classes=1 Ø§Ø³ØªØŒ BCEWithLogitsLoss Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª
    criterion = nn.BCEWithLogitsLoss()
    
    # ÙÙ‚Ø· Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ Ø±Ø§ train Ú©Ù†ÛŒÙ… (optional)
    # Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ØŒ Ù‡Ù…Ù‡ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ Ø±Ø§ train Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)
    
    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer, T_0=5, T_mult=2, eta_min=1e-6
    )
    
    # Ø¢Ù…ÙˆØ²Ø´
    print("\n" + "="*70)
    print("ğŸ“ Ø´Ø±ÙˆØ¹ Ø¢Ù…ÙˆØ²Ø´")
    print("="*70)
    
    best_val_acc = 0.0
    best_model_path = '/kaggle/working/best_pruned_finetuned.pt'
    
    for epoch in range(NUM_EPOCHS):
        print(f"\nğŸ“ Epoch {epoch+1}/{NUM_EPOCHS}")
        print(f"   Learning Rate: {optimizer.param_groups[0]['lr']:.6f}")
        print("-" * 70)
        
        # Ø¢Ù…ÙˆØ²Ø´
        train_loss, train_acc = train_epoch(
            model, train_loader, criterion, optimizer, DEVICE, ACCUMULATION_STEPS
        )
        print(f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%")
        
        # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
        val_loss, val_acc = validate(model, val_loader, criterion, DEVICE)
        print(f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%")
        
        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Learning Rate
        scheduler.step()
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'masks': checkpoint['masks'], # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§
                'optimizer_state_dict': optimizer.state_dict(),
                'val_acc': val_acc,
                'train_acc': train_acc,
                'total_params': total_params
            }, best_model_path)
            print(f"ğŸ’¾ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ (Val Acc: {val_acc:.2f}%)")
    
    # ØªØ³Øª Ù†Ù‡Ø§ÛŒÛŒ
    print("\n" + "="*70)
    print("ğŸ§ª ØªØ³Øª Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„")
    print("="*70)
    
    best_checkpoint = torch.load(best_model_path)
    model.load_state_dict(best_checkpoint['model_state_dict'])
    
    test_loss, test_acc = validate(model, test_loader, criterion, DEVICE)
    print(f"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%")
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ
    final_model_path = '/kaggle/working/final_pruned_finetuned.pt'
    torch.save({
        'model_state_dict': model.state_dict(),
        'masks': checkpoint['masks'], # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§
        'test_acc': test_acc,
        'best_val_acc': best_val_acc,
        'total_params': total_params,
        'model_architecture': 'ResNet_50_pruned_hardfakevsreal'
    }, final_model_path)
    
    print(f"\nâœ… Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ Ø¯Ø± {final_model_path} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
    print(f"ğŸ“Š Ø¨Ù‡ØªØ±ÛŒÙ† Ø¯Ù‚Øª Validation: {best_val_acc:.2f}%")
    print(f"ğŸ“Š Ø¯Ù‚Øª Test: {test_acc:.2f}%")
    print("\n" + "="*70)
    print("ğŸ‰ Fine-tuning Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!")
    print("="*70)

if __name__ == "__main__":
    main()
