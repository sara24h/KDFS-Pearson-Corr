import torch
import os
from model.pruned_model.ResNet_pruned import ResNet_50_pruned_hardfakevsreal

input_save_path = '/kaggle/working/140k-resnet50_pruned_model_learnable_masks.pt'
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

output_save_path = '/kaggle/working/140k_final.pt'

try:
    # Ø§Ù„Ù) Ù„ÙˆØ¯ Ú†Ú©â€ŒÙ¾ÙˆÛŒÙ†Øª Ú©Ø§Ù…Ù„ ÙˆØ±ÙˆØ¯ÛŒ
    checkpoint_loaded = torch.load(input_save_path, map_location=device)

    # Ø¨) Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
    model_state_dict = checkpoint_loaded['model_state_dict']
    masks = checkpoint_loaded['masks']
    
    # Ø¬) Ø³Ø§Ø®Øª Ù…Ø¯Ù„ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§
    model_pruned = ResNet_50_pruned_hardfakevsreal(masks=masks)
    
    # Ø¯) Ù„ÙˆØ¯ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡
    model_pruned.load_state_dict(model_state_dict)
    
    model_pruned = model_pruned.to(device)
    model_pruned.eval()
    
    total_params = sum(p.numel() for p in model_pruned.parameters())
    print("âœ… Ù…Ø¯Ù„ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ùˆ Ù„ÙˆØ¯ Ø´Ø¯!")
    print(f"ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§: {total_params:,}")

    print("\n" + "="*70)
    print("ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒâ€ŒØ´Ø¯Ù‡...")
    print("="*70)

    checkpoint_to_save = {
        'model_state_dict': model_pruned.state_dict(),
        'masks': masks, # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ø¢Ø³Ø§Ù† Ø¯Ø± Ø¢ÛŒÙ†Ø¯Ù‡
        'total_params': total_params,
        'model_architecture': 'ResNet_50_pruned_hardfakevsreal'
    }
    
    torch.save(checkpoint_to_save, output_save_path)
    
    # Ú†Ø§Ù¾ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡
    file_size_mb = os.path.getsize(output_save_path) / (1024 * 1024)
    print(f"âœ… Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± {output_save_path} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
    print(f"Ø­Ø¬Ù… ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡: {file_size_mb:.2f} MB")
    
    print("\n" + "="*70)
    print("Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ù…Ø¯Ù„ Ù‡Ø±Ø³â€ŒØ´Ø¯Ù‡ (ResNet_50_pruned_hardfakevsreal)")
    print("="*70)
    print(model_pruned)
    
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù„ÙˆØ¯ ÛŒØ§ Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„: {e}")
